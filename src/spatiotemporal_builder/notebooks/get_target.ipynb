{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from typing import TypedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandera as pa\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "from zoneinfo import ZoneInfo, available_timezones\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83, 4)\n",
      "process df_websirenes['latitude'] df_websirenes['longitude'] and from float64 to str since it will be key:\n",
      "object\n",
      "object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_estacao</th>\n",
       "      <th>estacao</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>Ladeira dos Tabajaras</td>\n",
       "      <td>-22.9617</td>\n",
       "      <td>-43.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>Cabritos 1</td>\n",
       "      <td>-22.9647</td>\n",
       "      <td>-43.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>Guararapes 1</td>\n",
       "      <td>-22.9447</td>\n",
       "      <td>-43.208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>Liberdade 1</td>\n",
       "      <td>-22.9266</td>\n",
       "      <td>-43.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>Salgueiro 1</td>\n",
       "      <td>-22.9302</td>\n",
       "      <td>-43.226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_estacao                estacao  latitude longitude\n",
       "0          33  Ladeira dos Tabajaras  -22.9617   -43.188\n",
       "1           8             Cabritos 1  -22.9647   -43.195\n",
       "2          26           Guararapes 1  -22.9447   -43.208\n",
       "3          34            Liberdade 1  -22.9266   -43.218\n",
       "4          64            Salgueiro 1  -22.9302   -43.226"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_df_websirenes_from_parquet(parquet_file: str = \"websirenes_stations.parquet\"):\n",
    "    df_websirenes = pd.read_parquet(parquet_file)\n",
    "    df_websirenes.drop(columns=[\"estacao_desc\"], inplace=True)\n",
    "    return df_websirenes\n",
    "\n",
    "\n",
    "df_websirenes = get_df_websirenes_from_parquet()\n",
    "print(df_websirenes.shape)\n",
    "\n",
    "df_websirenes.estacao = df_websirenes.estacao.str.strip()\n",
    "print(\n",
    "    \"process df_websirenes['latitude'] df_websirenes['longitude'] and from float64 to str since it will be key:\"\n",
    ")\n",
    "df_websirenes[\"latitude\"] = df_websirenes[\"latitude\"].apply(lambda x: str(x))\n",
    "df_websirenes[\"longitude\"] = df_websirenes[\"longitude\"].apply(lambda x: str(x))\n",
    "\n",
    "print(df_websirenes[\"latitude\"].dtype)\n",
    "print(df_websirenes[\"longitude\"].dtype)\n",
    "\n",
    "df_websirenes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The UTC offset for America/Sao_Paulo is -0300\n",
      "{'America/St_Lucia', 'Antarctica/Palmer', 'Asia/Tashkent', 'Asia/Vladivostok', 'America/Indiana/Knox', 'Factory', 'Pacific/Majuro', 'Portugal', 'EST5EDT', 'Pacific/Galapagos', 'Etc/GMT+1', 'Africa/Nouakchott', 'Africa/Algiers', 'MST', 'America/Porto_Velho', 'Etc/UTC', 'America/Bahia_Banderas', 'Australia/Adelaide', 'Antarctica/Mawson', 'US/Eastern', 'America/Nipigon', 'America/Jamaica', 'America/Coral_Harbour', 'America/Juneau', 'PRC', 'America/Mazatlan', 'Asia/Katmandu', 'Etc/Zulu', 'Asia/Vientiane', 'Atlantic/Canary', 'Etc/GMT+0', 'GB', 'America/North_Dakota/New_Salem', 'America/Cuiaba', 'Europe/Luxembourg', 'Etc/GMT+7', 'America/Fort_Wayne', 'Asia/Rangoon', 'Europe/Tiraspol', 'Pacific/Marquesas', 'Africa/Kinshasa', 'America/St_Johns', 'Asia/Ho_Chi_Minh', 'Kwajalein', 'America/Argentina/Jujuy', 'Indian/Chagos', 'build/etc/localtime', 'Pacific/Pohnpei', 'Etc/GMT+10', 'Africa/Lusaka', 'Etc/GMT+8', 'America/Buenos_Aires', 'Poland', 'Europe/Zaporozhye', 'Asia/Makassar', 'Pacific/Pitcairn', 'America/Rio_Branco', 'Europe/Istanbul', 'America/Cayman', 'Atlantic/Bermuda', 'Africa/Maseru', 'Atlantic/Madeira', 'Africa/Kigali', 'Africa/Mogadishu', 'Europe/Amsterdam', 'Canada/Newfoundland', 'Etc/GMT+11', 'America/Montreal', 'America/Cancun', 'America/Guatemala', 'Asia/Jakarta', 'UTC', 'US/Pacific', 'America/Argentina/Ushuaia', 'Africa/Johannesburg', 'Asia/Yangon', 'America/Anchorage', 'America/Indiana/Vevay', 'Etc/GMT-12', 'America/Argentina/Rio_Gallegos', 'America/Rainy_River', 'Hongkong', 'US/Aleutian', 'Europe/Podgorica', 'America/Iqaluit', 'Europe/Helsinki', 'America/Kralendijk', 'Indian/Mayotte', 'Africa/Tripoli', 'Pacific/Guam', 'Asia/Chungking', 'Asia/Kabul', 'Antarctica/South_Pole', 'Libya', 'America/Toronto', 'Pacific/Kosrae', 'Europe/Nicosia', 'America/Cordoba', 'Jamaica', 'Africa/Douala', 'America/Godthab', 'America/Antigua', 'Australia/Melbourne', 'Etc/GMT+2', 'America/Vancouver', 'Antarctica/Troll', 'Europe/Astrakhan', 'Etc/GMT+3', 'America/Managua', 'Turkey', 'WET', 'Africa/Asmara', 'Europe/Copenhagen', 'Africa/Niamey', 'Africa/Lome', 'US/Alaska', 'GMT0', 'Asia/Dhaka', 'America/Lower_Princes', 'America/Cayenne', 'Africa/Juba', 'Asia/Dili', 'America/Resolute', 'America/Blanc-Sablon', 'GMT+0', 'America/Louisville', 'Singapore', 'America/Bogota', 'Africa/Harare', 'Brazil/East', 'America/Martinique', 'America/Tortola', 'Brazil/West', 'US/Samoa', 'America/Hermosillo', 'Canada/Pacific', 'Africa/Dar_es_Salaam', 'Pacific/Rarotonga', 'America/Merida', 'Asia/Hong_Kong', 'Africa/Ceuta', 'Australia/West', 'Asia/Seoul', 'Brazil/Acre', 'America/Moncton', 'Asia/Pyongyang', 'Atlantic/Azores', 'Pacific/Funafuti', 'America/North_Dakota/Center', 'Africa/Malabo', 'Antarctica/Syowa', 'Pacific/Port_Moresby', 'Europe/Kiev', 'Japan', 'Africa/Maputo', 'America/Chicago', 'Etc/GMT+5', 'Etc/Universal', 'Asia/Ulaanbaatar', 'America/Boise', 'Pacific/Niue', 'Africa/Bangui', 'W-SU', 'Iceland', 'Australia/Darwin', 'Europe/Chisinau', 'Asia/Famagusta', 'CET', 'Africa/Bissau', 'Africa/Brazzaville', 'PST8PDT', 'America/Rosario', 'America/Manaus', 'America/Atikokan', 'Asia/Tel_Aviv', 'Etc/GMT-8', 'Etc/GMT-9', 'Africa/Lagos', 'Eire', 'Asia/Ujung_Pandang', 'Australia/South', 'Asia/Aden', 'America/Cambridge_Bay', 'Asia/Dubai', 'America/Belize', 'America/Indianapolis', 'Asia/Chongqing', 'Africa/Abidjan', 'Atlantic/Cape_Verde', 'Europe/Stockholm', 'Europe/Sarajevo', 'Africa/Cairo', 'Asia/Bangkok', 'America/Asuncion', 'America/Recife', 'Asia/Barnaul', 'Europe/Ulyanovsk', 'Indian/Reunion', 'Europe/Vilnius', 'America/Knox_IN', 'Atlantic/St_Helena', 'America/St_Kitts', 'Asia/Tbilisi', 'Africa/Libreville', 'Asia/Chita', 'America/Santo_Domingo', 'Australia/Perth', 'Pacific/Nauru', 'America/Havana', 'Australia/Victoria', 'Australia/Lord_Howe', 'America/Argentina/San_Juan', 'America/Punta_Arenas', 'Asia/Harbin', 'America/Belem', 'America/Port-au-Prince', 'America/Mendoza', 'America/North_Dakota/Beulah', 'America/St_Vincent', 'Europe/Zagreb', 'Europe/Madrid', 'Israel', 'America/Dominica', 'Asia/Baghdad', 'Australia/Yancowinna', 'Navajo', 'ROK', 'Indian/Cocos', 'Canada/Eastern', 'America/Campo_Grande', 'US/East-Indiana', 'America/Santarem', 'America/La_Paz', 'America/Marigot', 'Pacific/Apia', 'Pacific/Tahiti', 'Europe/Mariehamn', 'America/Guadeloupe', 'Asia/Phnom_Penh', 'US/Michigan', 'America/Phoenix', 'Indian/Maldives', 'Chile/EasterIsland', 'America/Port_of_Spain', 'Asia/Macau', 'Australia/Currie', 'America/Glace_Bay', 'Pacific/Guadalcanal', 'Asia/Manila', 'America/Porto_Acre', 'Asia/Baku', 'America/Sao_Paulo', 'Asia/Novosibirsk', 'Antarctica/Rothera', 'Asia/Muscat', 'Africa/Windhoek', 'Brazil/DeNoronha', 'America/Mexico_City', 'America/Argentina/Cordoba', 'US/Indiana-Starke', 'Africa/Ndjamena', 'Asia/Ashkhabad', 'America/Anguilla', 'America/Ojinaga', 'Atlantic/Reykjavik', 'EST', 'Asia/Kashgar', 'Asia/Hebron', 'Etc/GMT+6', 'Pacific/Efate', 'America/Panama', 'GMT', 'Etc/GMT-10', 'Africa/Bujumbura', 'America/Maceio', 'Etc/GMT-1', 'Europe/Bucharest', 'Australia/Broken_Hill', 'America/Menominee', 'Cuba', 'America/Montserrat', 'America/Yellowknife', 'America/Winnipeg', 'America/Indiana/Vincennes', 'Asia/Qyzylorda', 'America/Fortaleza', 'America/Santa_Isabel', 'Etc/GMT0', 'Asia/Nicosia', 'America/Thule', 'Pacific/Samoa', 'Mexico/General', 'Asia/Damascus', 'Asia/Taipei', 'Africa/Banjul', 'Europe/Saratov', 'Indian/Christmas', 'Chile/Continental', 'Europe/Budapest', 'Europe/London', 'Asia/Ust-Nera', 'Asia/Bishkek', 'Asia/Aqtau', 'Pacific/Kiritimati', 'America/Bahia', 'US/Mountain', 'America/Costa_Rica', 'Europe/Andorra', 'America/Guyana', 'Canada/Atlantic', 'America/Aruba', 'Europe/Kaliningrad', 'Asia/Yerevan', 'Asia/Riyadh', 'Africa/Addis_Ababa', 'ROC', 'Pacific/Kwajalein', 'Antarctica/DumontDUrville', 'Europe/Skopje', 'America/Dawson_Creek', 'Africa/Luanda', 'Canada/Yukon', 'Africa/El_Aaiun', 'Arctic/Longyearbyen', 'Europe/Ljubljana', 'Asia/Bahrain', 'America/Chihuahua', 'Africa/Djibouti', 'America/Metlakatla', 'Asia/Kamchatka', 'America/Tijuana', 'Australia/NSW', 'Zulu', 'Etc/GMT-2', 'Africa/Conakry', 'HST', 'Europe/Belfast', 'America/Argentina/La_Rioja', 'America/Thunder_Bay', 'Europe/Athens', 'America/Fort_Nelson', 'Asia/Amman', 'America/Creston', 'Europe/Bratislava', 'Europe/Tallinn', 'America/Barbados', 'America/Grand_Turk', 'Europe/Lisbon', 'Indian/Antananarivo', 'America/Virgin', 'Pacific/Kanton', 'Asia/Shanghai', 'Pacific/Saipan', 'America/Argentina/San_Luis', 'Pacific/Wallis', 'America/Curacao', 'America/St_Barthelemy', 'Asia/Samarkand', 'Asia/Kathmandu', 'Pacific/Tarawa', 'Pacific/Chuuk', 'Antarctica/Vostok', 'America/Regina', 'America/Montevideo', 'Canada/Saskatchewan', 'America/Swift_Current', 'America/Kentucky/Monticello', 'Europe/Minsk', 'Pacific/Norfolk', 'Europe/Malta', 'America/Halifax', 'America/Kentucky/Louisville', 'America/Nuuk', 'Pacific/Gambier', 'Etc/GMT+4', 'America/Shiprock', 'Universal', 'Europe/Monaco', 'Asia/Atyrau', 'Asia/Dushanbe', 'Asia/Yakutsk', 'Australia/Queensland', 'Africa/Bamako', 'Asia/Qostanay', 'America/Indiana/Winamac', 'UCT', 'Europe/Rome', 'Asia/Oral', 'Asia/Magadan', 'Asia/Kuching', 'Africa/Accra', 'America/Puerto_Rico', 'Etc/GMT+12', 'Etc/GMT', 'Asia/Colombo', 'America/Nassau', 'Asia/Omsk', 'Indian/Mauritius', 'Etc/GMT-5', 'MET', 'Mexico/BajaNorte', 'Pacific/Truk', 'America/Indiana/Indianapolis', 'Asia/Dacca', 'Asia/Srednekolymsk', 'America/Argentina/Catamarca', 'Australia/LHI', 'America/Goose_Bay', 'America/Scoresbysund', 'America/Inuvik', 'Asia/Sakhalin', 'Africa/Tunis', 'Asia/Istanbul', 'America/Whitehorse', 'Australia/Canberra', 'US/Arizona', 'Asia/Hovd', 'Asia/Kolkata', 'America/Boa_Vista', 'Asia/Kuwait', 'Pacific/Midway', 'America/Pangnirtung', 'Africa/Timbuktu', 'Canada/Mountain', 'Asia/Anadyr', 'GB-Eire', 'America/Eirunepe', 'Asia/Thimbu', 'Pacific/Palau', 'Asia/Gaza', 'Australia/Brisbane', 'Australia/Hobart', 'Australia/Lindeman', 'America/Argentina/Tucuman', 'Asia/Ashgabat', 'Asia/Jayapura', 'Asia/Irkutsk', 'US/Central', 'America/Tegucigalpa', 'Europe/Riga', 'America/Araguaina', 'Pacific/Honolulu', 'Pacific/Johnston', 'Pacific/Chatham', 'Africa/Casablanca', 'Antarctica/Casey', 'America/El_Salvador', 'America/Los_Angeles', 'America/Denver', 'America/Grenada', 'Pacific/Ponape', 'Asia/Calcutta', 'Asia/Singapore', 'Pacific/Bougainville', 'Etc/GMT-11', 'Europe/Vienna', 'Europe/Volgograd', 'Atlantic/Jan_Mayen', 'Asia/Tokyo', 'Europe/Warsaw', 'America/Matamoros', 'EET', 'Indian/Kerguelen', 'America/Jujuy', 'Asia/Yekaterinburg', 'Africa/Khartoum', 'America/New_York', 'Atlantic/Faroe', 'Etc/GMT-6', 'America/Indiana/Tell_City', 'Etc/GMT-3', 'America/St_Thomas', 'America/Noronha', 'Asia/Karachi', 'Etc/GMT-14', 'America/Indiana/Petersburg', 'America/Ensenada', 'Antarctica/Davis', 'Europe/Belgrade', 'America/Lima', 'Canada/Central', 'Europe/San_Marino', 'Asia/Tehran', 'Asia/Brunei', 'Europe/Busingen', 'America/Atka', 'Indian/Comoro', 'America/Detroit', 'Pacific/Auckland', 'Asia/Aqtobe', 'Greenwich', 'Europe/Oslo', 'America/Miquelon', 'Europe/Sofia', 'Etc/GMT-4', 'Europe/Kyiv', 'Europe/Berlin', 'Etc/Greenwich', 'Europe/Kirov', 'Iran', 'Asia/Choibalsan', 'Atlantic/South_Georgia', 'MST7MDT', 'Africa/Porto-Novo', 'Mexico/BajaSur', 'Europe/Paris', 'Africa/Blantyre', 'Asia/Khandyga', 'America/Edmonton', 'Europe/Jersey', 'Asia/Ulan_Bator', 'Africa/Lubumbashi', 'Pacific/Fiji', 'Antarctica/Macquarie', 'Asia/Macao', 'Asia/Almaty', 'Asia/Kuala_Lumpur', 'Asia/Saigon', 'America/Argentina/Mendoza', 'Antarctica/McMurdo', 'America/Argentina/Buenos_Aires', 'Atlantic/Stanley', 'Europe/Gibraltar', 'America/Argentina/Salta', 'Pacific/Noumea', 'America/Sitka', 'Asia/Jerusalem', 'Europe/Moscow', 'America/Catamarca', 'Europe/Vaduz', 'Africa/Ouagadougou', 'America/Argentina/ComodRivadavia', 'Pacific/Pago_Pago', 'CST6CDT', 'Australia/ACT', 'America/Danmarkshavn', 'Asia/Novokuznetsk', 'Asia/Tomsk', 'Asia/Pontianak', 'Europe/Guernsey', 'America/Adak', 'Asia/Qatar', 'Europe/Prague', 'America/Caracas', 'Africa/Freetown', 'Africa/Asmera', 'Etc/GMT-7', 'Europe/Brussels', 'Europe/Zurich', 'Europe/Vatican', 'Asia/Beirut', 'Africa/Gaborone', 'Asia/Urumqi', 'America/Nome', 'Europe/Simferopol', 'Indian/Mahe', 'Egypt', 'Etc/GMT+9', 'Etc/GMT-13', 'Africa/Mbabane', 'Europe/Samara', 'Europe/Uzhgorod', 'Pacific/Enderbury', 'Europe/Dublin', 'America/Dawson', 'Pacific/Tongatapu', 'GMT-0', 'Europe/Isle_of_Man', 'Australia/Eucla', 'Africa/Dakar', 'Etc/UCT', 'NZ-CHAT', 'Africa/Kampala', 'America/Santiago', 'Pacific/Yap', 'Australia/Sydney', 'Africa/Monrovia', 'Australia/North', 'Africa/Sao_Tome', 'America/Monterrey', 'Australia/Tasmania', 'Etc/GMT-0', 'Asia/Thimphu', 'US/Hawaii', 'America/Yakutat', 'Pacific/Wake', 'Atlantic/Faeroe', 'Pacific/Fakaofo', 'Asia/Krasnoyarsk', 'America/Ciudad_Juarez', 'America/Guayaquil', 'Pacific/Easter', 'Africa/Nairobi', 'NZ', 'Europe/Tirane', 'America/Indiana/Marengo', 'America/Rankin_Inlet', 'America/Paramaribo'}\n",
      "Datetime object: 2024-08-21 21:40:55-03:00\n",
      "Timezone info: UTC-03:00\n",
      "Datetime object in UTC: 2024-08-22 00:40:55+00:00\n",
      "Timezone info in UTC: UTC\n",
      "Timestamp('2024-08-21 21:40:55-0300', tz='UTC-03:00')\n",
      "Timestamp('2024-08-22 00:40:55+0000', tz='UTC')\n",
      "Timestamp('2024-08-22 00:40:55')\n",
      "datetime64[ns, UTC]\n",
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "def get_UTC_offset_from_timezone_name(timezone_name: str) -> str:\n",
    "    now = datetime.now(ZoneInfo(timezone_name))\n",
    "    return now.strftime(\"%z\")\n",
    "\n",
    "\n",
    "timezone_name = \"America/Sao_Paulo\"\n",
    "print(f\"The UTC offset for {timezone_name} is {get_UTC_offset_from_timezone_name(timezone_name)}\")\n",
    "print(available_timezones())\n",
    "\n",
    "today_string = \"2024-08-21 21:40:55-0300\"\n",
    "dt = pd.to_datetime(datetime.strptime(today_string, \"%Y-%m-%d %H:%M:%S%z\"))\n",
    "\n",
    "print(\"Datetime object:\", dt)\n",
    "print(\"Timezone info:\", dt.tzinfo)\n",
    "dt_utc = dt.tz_convert(\"UTC\")\n",
    "print(\"Datetime object in UTC:\", dt_utc)\n",
    "print(\"Timezone info in UTC:\", dt_utc.tzinfo)\n",
    "\n",
    "print(repr(dt))\n",
    "print(repr(dt_utc))\n",
    "print(repr(pd.to_datetime(today_string, format=\"%Y-%m-%d %H:%M:%S%z\").tz_convert(None)))\n",
    "print(\n",
    "    pd.Series([pd.to_datetime(today_string, format=\"%Y-%m-%d %H:%M:%S%z\").tz_convert(\"UTC\")]).dtype\n",
    ")\n",
    "print(\n",
    "    pd.Series([pd.to_datetime(today_string, format=\"%Y-%m-%d %H:%M:%S%z\").tz_convert(None)]).dtype\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebSireneSchema(pa.DataFrameModel):\n",
    "    horaLeitura: pd.Timestamp\n",
    "    nome: str\n",
    "    m15: float = pa.Field(nullable=True)  # ge=0, but has -99.99 values\n",
    "    m30: float = pa.Field(nullable=True)\n",
    "    h01: float = pa.Field(nullable=True)\n",
    "    h02: float = pa.Field(nullable=True)\n",
    "    h03: float = pa.Field(nullable=True)\n",
    "    h04: float = pa.Field(nullable=True)\n",
    "    h24: float = pa.Field(nullable=True)\n",
    "    h96: float = pa.Field(nullable=True)\n",
    "    station_id: int\n",
    "\n",
    "\n",
    "class WebSirenesParser:\n",
    "    minimum_date = pd.Timestamp.max\n",
    "    maximum_date = pd.Timestamp.min\n",
    "\n",
    "    def list_files(self) -> list[str]:\n",
    "        return os.listdir(\"websirenes_defesa_civil\")\n",
    "\n",
    "    def _get_name_pattern(self) -> str:\n",
    "        \"\"\"\n",
    "        Example:\n",
    "            BARRA DA TIJUCA 3 2021-08-01 00:00:00-03 null 2 ... matches BARRA DA TIJUCA 3\n",
    "        Returns:\n",
    "            str: regex pattern to extract name from line\n",
    "        \"\"\"\n",
    "        return r\"^(?P<name>.+?)(?=\\s+\\d{4}-\\d{2}-\\d{2})\"\n",
    "\n",
    "    def _get_date_pattern(self) -> str:\n",
    "        \"\"\"\n",
    "        Example:\n",
    "            BARRA DA TIJUCA 3 2021-08-01 00:00:00-03 null 2 ... matches 2021-08-01 00:00:00-03\n",
    "        Returns:\n",
    "            str: regex pattern to extract date from line\n",
    "        \"\"\"\n",
    "        return r\"(?P<date>\\d{4}-\\d{2}-\\d{2}\\s\\d{2}:\\d{2}:\\d{2}-\\d{2})\"\n",
    "\n",
    "    def _get_timeframe_pattern(self) -> str:\n",
    "        \"\"\"\n",
    "        Example:\n",
    "            BARRA DA TIJUCA 3 2021-08-01 00:00:00-03 null 2 3 4 5 6 7 8 ... matches null 2 3 4 5 6 7 8\n",
    "        Returns:\n",
    "            str: regex pattern to extract timeframe from line\n",
    "        \"\"\"\n",
    "        return r\"(?P<timeframe>.+)$\"\n",
    "\n",
    "    def _get_complete_pattern(self) -> str:\n",
    "        \"\"\"\n",
    "        Example:\n",
    "            BARRA DA TIJUCA 3 2021-08-01 00:00:00-03 null 2 3 4 5 6 7 8 ...\n",
    "            matches:\n",
    "                BARRA DA TIJUCA 3 at group 'name'\n",
    "                2021-08-01 00:00:00-03 at group 'date'\n",
    "                null 2 3 4 5 6 7 8 at group 'timeframe'\n",
    "        Returns:\n",
    "            str: regex pattern to extract name, date and timeframe from line\n",
    "        \"\"\"\n",
    "        return rf\"{self._get_name_pattern()}\\s+{self._get_date_pattern()}\\s+{self._get_timeframe_pattern()}\"\n",
    "\n",
    "    def _extract_features(self, line: str) -> tuple:\n",
    "        \"\"\"\n",
    "        Extracts features from a line of the txt file using regex patterns.\n",
    "        It extracts:\n",
    "            - name\n",
    "            - date\n",
    "            - m15\n",
    "            - m30\n",
    "            - h01\n",
    "            - h02\n",
    "            - h03\n",
    "            - h04\n",
    "            - h24\n",
    "            - h96\n",
    "            - station_id\n",
    "        \"\"\"\n",
    "        complete_pattern = self._get_complete_pattern()\n",
    "\n",
    "        match = re.search(complete_pattern, line)\n",
    "\n",
    "        if match is None:\n",
    "            raise ValueError(f\"Could not extract features from line: {line}\")\n",
    "\n",
    "        name = match.group(\"name\")\n",
    "        date = match.group(\"date\") + \"00\"\n",
    "        timeframe = match.group(\"timeframe\")\n",
    "\n",
    "        m15, m30, h01, h02, h03, h04, h24, h96, station_id = [\n",
    "            np.nan if x == \"null\" else float(x.replace(\",\", \".\")) if \",\" in x else float(x)\n",
    "            for x in timeframe.strip().split()\n",
    "        ]\n",
    "\n",
    "        return (\n",
    "            name,\n",
    "            date,\n",
    "            m15,\n",
    "            m30,\n",
    "            h01,\n",
    "            h02,\n",
    "            h03,\n",
    "            h04,\n",
    "            h24,\n",
    "            h96,\n",
    "            int(station_id),\n",
    "        )\n",
    "\n",
    "    def _parse_txt_file(self, file_path: str) -> tuple[list[str], list[tuple]]:\n",
    "        try:\n",
    "            file_data: list[tuple] = []\n",
    "            with open(file_path, \"r\", encoding=\"utf-8-sig\") as file:\n",
    "                header = file.readline().strip().split()\n",
    "                for line in file:\n",
    "                    file_data.append(self._extract_features(line))\n",
    "            return header, file_data\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing file {file_path}: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def read_station_name_id_txt_file(self, file_path: str) -> tuple[str, int]:\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8-sig\") as file:\n",
    "                _header = file.readline().strip().split()\n",
    "                (\n",
    "                    nome,\n",
    "                    horaLeitura,\n",
    "                    m15,\n",
    "                    m30,\n",
    "                    h01,\n",
    "                    h02,\n",
    "                    h03,\n",
    "                    h04,\n",
    "                    h24,\n",
    "                    h96,\n",
    "                    station_id,\n",
    "                ) = self._extract_features(file.readline())\n",
    "                return nome, station_id\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing file {file_path}: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def get_dataframe(self, file_path: str) -> pd.DataFrame:\n",
    "        header, file_data = self._parse_txt_file(file_path)\n",
    "        df = pd.DataFrame(file_data, columns=header)\n",
    "        df[\"horaLeitura\"] = pd.to_datetime(\n",
    "            df[\"horaLeitura\"], format=\"%Y-%m-%d %H:%M:%S%z\"\n",
    "        ).dt.tz_convert(None)\n",
    "        df.rename(columns={\"id\": \"station_id\"}, inplace=True)\n",
    "        WebSireneSchema.validate(df)\n",
    "        df.set_index(\"horaLeitura\", inplace=True)\n",
    "        return df\n",
    "\n",
    "    def assert_is_sorted_by_date(self, df: pd.DataFrame) -> None:\n",
    "        assert df.index.is_monotonic_increasing, \"DataFrame index is not sorted by date\"\n",
    "\n",
    "\n",
    "websirenes_parser = WebSirenesParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Juramento 2', 'station_id': 1},\n",
       " {'name': 'Cachoeirinha 1', 'station_id': 100},\n",
       " {'name': 'Cantagalo 1', 'station_id': 101},\n",
       " {'name': 'Engenho da Rainha 2', 'station_id': 102},\n",
       " {'name': 'Travessa Antonina 1', 'station_id': 106}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class StationNameId(TypedDict):\n",
    "    name: str\n",
    "    station_id: int\n",
    "\n",
    "\n",
    "def get_stations_name_id() -> list[StationNameId]:\n",
    "    stations_name_id: list[StationNameId] = []\n",
    "    for file in websirenes_parser.list_files():\n",
    "        name, station_id = websirenes_parser.read_station_name_id_txt_file(\n",
    "            os.path.join(\"websirenes_defesa_civil\", file)\n",
    "        )\n",
    "        stations_name_id.append(StationNameId(name=name, station_id=station_id))\n",
    "    return stations_name_id\n",
    "\n",
    "\n",
    "stations_name_id: list[StationNameId] = get_stations_name_id()\n",
    "stations_name_id[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station Travessa Antonina 1 not found in parquet\n",
      "\n",
      "    Stations not matching id by name:\n",
      "    [{'name_in_txt': 'Juramento 2', 'name_in_parquet': 'Juramento 2', 'station_id_in_txt': 1, 'station_id_in_parquet': 32}, {'name_in_txt': 'Cachoeirinha 1', 'name_in_parquet': 'Cachoeirinha 1', 'station_id_in_txt': 100, 'station_id_in_parquet': 9}, {'name_in_txt': 'Cantagalo 1', 'name_in_parquet': 'Cantagalo 1', 'station_id_in_txt': 101, 'station_id_in_parquet': 10}, {'name_in_txt': 'Engenho da Rainha 2', 'name_in_parquet': 'Engenho da Rainha 2', 'station_id_in_txt': 102, 'station_id_in_parquet': 20}, {'name_in_txt': 'São João 4', 'name_in_parquet': 'São João 4', 'station_id_in_txt': 109, 'station_id_in_parquet': 70}, {'name_in_txt': 'Andaraí 1', 'name_in_parquet': 'Andaraí 1', 'station_id_in_txt': 11, 'station_id_in_parquet': 3}, {'name_in_txt': 'Parque Nova Maracá 1', 'name_in_parquet': 'Parque Nova Maracá 1', 'station_id_in_txt': 111, 'station_id_in_parquet': 51}, {'name_in_txt': 'São João 2', 'name_in_parquet': 'São João 2', 'station_id_in_txt': 113, 'station_id_in_parquet': 69}, {'name_in_txt': 'Mineiros 1', 'name_in_parquet': 'Mineiros 1', 'station_id_in_txt': 114, 'station_id_in_parquet': 39}, {'name_in_txt': 'Borel 2', 'name_in_parquet': 'Borel 2', 'station_id_in_txt': 115, 'station_id_in_parquet': 6}, {'name_in_txt': 'Joaquim de Queiroz 1', 'name_in_parquet': 'Joaquim de Queiroz 1', 'station_id_in_txt': 116, 'station_id_in_parquet': 30}, {'name_in_txt': 'Unidos de Santa Tereza 3', 'name_in_parquet': 'Unidos de Santa Tereza 3', 'station_id_in_txt': 117, 'station_id_in_parquet': 77}, {'name_in_txt': 'Chácara do Céu 1', 'name_in_parquet': 'Chácara do Céu 1', 'station_id_in_txt': 118, 'station_id_in_parquet': 15}, {'name_in_txt': 'Alemão 1', 'name_in_parquet': 'Alemão 1', 'station_id_in_txt': 12, 'station_id_in_parquet': 2}, {'name_in_txt': 'Santos Rodrigues 2 / Azevedo Lima 1', 'name_in_parquet': 'Santos Rodrigues 2 / Azevedo Lima 1', 'station_id_in_txt': 120, 'station_id_in_parquet': 67}, {'name_in_txt': 'Sumaré 1', 'name_in_parquet': 'Sumaré 1', 'station_id_in_txt': 121, 'station_id_in_parquet': 75}, {'name_in_txt': 'Cabritos 1', 'name_in_parquet': 'Cabritos 1', 'station_id_in_txt': 123, 'station_id_in_parquet': 8}, {'name_in_txt': 'Pavão-Pavãozinho 2', 'name_in_parquet': 'Pavão-Pavãozinho 2', 'station_id_in_txt': 126, 'station_id_in_parquet': 54}, {'name_in_txt': 'Formiga 1', 'name_in_parquet': 'Formiga 1', 'station_id_in_txt': 129, 'station_id_in_parquet': 24}, {'name_in_txt': 'Macacos 1', 'name_in_parquet': 'Macacos 1', 'station_id_in_txt': 132, 'station_id_in_parquet': 35}, {'name_in_txt': 'Caracol 1', 'name_in_parquet': 'Caracol 1', 'station_id_in_txt': 137, 'station_id_in_parquet': 11}, {'name_in_txt': 'Cotia 1', 'name_in_parquet': 'Cotia 1', 'station_id_in_txt': 139, 'station_id_in_parquet': 19}, {'name_in_txt': 'Nossa Senhora da Guia 1', 'name_in_parquet': 'Nossa Senhora da Guia 1', 'station_id_in_txt': 141, 'station_id_in_parquet': 42}, {'name_in_txt': 'Urubu 2', 'name_in_parquet': 'Urubu 2', 'station_id_in_txt': 145, 'station_id_in_parquet': 78}, {'name_in_txt': 'Rio das Pedras 2', 'name_in_parquet': 'Rio das Pedras 2', 'station_id_in_txt': 150, 'station_id_in_parquet': 58}, {'name_in_txt': 'Vila José de Anchieta 1', 'name_in_parquet': 'Vila José de Anchieta 1', 'station_id_in_txt': 152, 'station_id_in_parquet': 82}, {'name_in_txt': 'Prazeres 1', 'name_in_parquet': 'Prazeres 1', 'station_id_in_txt': 153, 'station_id_in_parquet': 56}, {'name_in_txt': 'Borel 3', 'name_in_parquet': 'Borel 3', 'station_id_in_txt': 158, 'station_id_in_parquet': 7}, {'name_in_txt': 'Rocinha 8', 'name_in_parquet': 'Rocinha 8', 'station_id_in_txt': 16, 'station_id_in_parquet': 61}, {'name_in_txt': 'Jamelão 2', 'name_in_parquet': 'Jamelão 2', 'station_id_in_txt': 161, 'station_id_in_parquet': 28}, {'name_in_txt': 'Tuiuti 2 / Telégrafos', 'name_in_parquet': 'Tuiuti 2 / Telégrafos', 'station_id_in_txt': 162, 'station_id_in_parquet': 76}, {'name_in_txt': 'Sapê 1', 'name_in_parquet': 'Sapê 1', 'station_id_in_txt': 163, 'station_id_in_parquet': 72}, {'name_in_txt': 'Nova Divinéia 1', 'name_in_parquet': 'Nova Divinéia 1', 'station_id_in_txt': 164, 'station_id_in_parquet': 44}, {'name_in_txt': 'Centro de Operações', 'name_in_parquet': 'Centro de Operações', 'station_id_in_txt': 165, 'station_id_in_parquet': 14}, {'name_in_txt': 'Ignácio Dias 1', 'name_in_parquet': 'Ignácio Dias 1', 'station_id_in_txt': 166, 'station_id_in_parquet': 27}, {'name_in_txt': 'Vidigal 3', 'name_in_parquet': 'Vidigal 3', 'station_id_in_txt': 17, 'station_id_in_parquet': 79}, {'name_in_txt': 'Escondidinho 1', 'name_in_parquet': 'Escondidinho 1', 'station_id_in_txt': 2, 'station_id_in_parquet': 21}, {'name_in_txt': 'Rocinha 1', 'name_in_parquet': 'Rocinha 1', 'station_id_in_txt': 20, 'station_id_in_parquet': 59}, {'name_in_txt': 'Rocinha 4', 'name_in_parquet': 'Rocinha 4', 'station_id_in_txt': 21, 'station_id_in_parquet': 60}, {'name_in_txt': 'Adeus 1', 'name_in_parquet': 'Adeus 1', 'station_id_in_txt': 22, 'station_id_in_parquet': 1}, {'name_in_txt': 'Baiana 1', 'name_in_parquet': 'Baiana 1', 'station_id_in_txt': 26, 'station_id_in_parquet': 4}, {'name_in_txt': 'Barão 1', 'name_in_parquet': 'Barão 1', 'station_id_in_txt': 27, 'station_id_in_parquet': 5}, {'name_in_txt': 'Sítio Pai João 1', 'name_in_parquet': 'Sítio Pai João 1', 'station_id_in_txt': 3, 'station_id_in_parquet': 74}, {'name_in_txt': 'Vila Pereira da Silva 1', 'name_in_parquet': 'Vila Pereira da Silva 1', 'station_id_in_txt': 32, 'station_id_in_parquet': 83}, {'name_in_txt': 'Comandante Luiz Souto 1', 'name_in_parquet': 'Comandante Luiz Souto 1', 'station_id_in_txt': 34, 'station_id_in_parquet': 18}, {'name_in_txt': 'Guaíba 1 / Vila Pequiri', 'name_in_parquet': 'Guaíba 1 / Vila Pequiri', 'station_id_in_txt': 35, 'station_id_in_parquet': 25}, {'name_in_txt': 'Ouro Preto 2', 'name_in_parquet': 'Ouro Preto 2', 'station_id_in_txt': 37, 'station_id_in_parquet': 46}, {'name_in_txt': 'Parque Alvorada 2', 'name_in_parquet': 'Parque Alvorada 2', 'station_id_in_txt': 38, 'station_id_in_parquet': 48}, {'name_in_txt': 'Morro do Céu 2 / Pretos Forros 1', 'name_in_parquet': 'Morro do Céu 2 / Pretos Forros 1', 'station_id_in_txt': 40, 'station_id_in_parquet': 41}, {'name_in_txt': 'Palmeiras 2', 'name_in_parquet': 'Palmeiras 2', 'station_id_in_txt': 41, 'station_id_in_parquet': 47}, {'name_in_txt': 'Liberdade 1', 'name_in_parquet': 'Liberdade 1', 'station_id_in_txt': 45, 'station_id_in_parquet': 34}, {'name_in_txt': 'Parque João Paulo II 1', 'name_in_parquet': 'Parque João Paulo II 1', 'station_id_in_txt': 47, 'station_id_in_parquet': 50}, {'name_in_txt': 'Matriz 1', 'name_in_parquet': 'Matriz 1', 'station_id_in_txt': 5, 'station_id_in_parquet': 38}, {'name_in_txt': 'São Miguel Arcanjo 1', 'name_in_parquet': 'São Miguel Arcanjo 1', 'station_id_in_txt': 7, 'station_id_in_parquet': 71}, {'name_in_txt': 'Parque Candelária 1', 'name_in_parquet': 'Parque Candelária 1', 'station_id_in_txt': 72, 'station_id_in_parquet': 49}, {'name_in_txt': 'Mangueira 1', 'name_in_parquet': 'Mangueira 1', 'station_id_in_txt': 73, 'station_id_in_parquet': 36}, {'name_in_txt': 'Matinha 1', 'name_in_parquet': 'Matinha 1', 'station_id_in_txt': 74, 'station_id_in_parquet': 37}, {'name_in_txt': 'Salgueiro 1', 'name_in_parquet': 'Salgueiro 1', 'station_id_in_txt': 75, 'station_id_in_parquet': 64}, {'name_in_txt': 'Parque Silva Vale 3', 'name_in_parquet': 'Parque Silva Vale 3', 'station_id_in_txt': 77, 'station_id_in_parquet': 52}, {'name_in_txt': 'Sereno 1', 'name_in_parquet': 'Sereno 1', 'station_id_in_txt': 78, 'station_id_in_parquet': 73}, {'name_in_txt': 'Guararapes 1', 'name_in_parquet': 'Guararapes 1', 'station_id_in_txt': 79, 'station_id_in_parquet': 26}, {'name_in_txt': 'Rua Brício de Moraes 1', 'name_in_parquet': 'Rua Brício de Moraes 1', 'station_id_in_txt': 8, 'station_id_in_parquet': 62}, {'name_in_txt': 'Chacrinha 1', 'name_in_parquet': 'Chacrinha 1', 'station_id_in_txt': 80, 'station_id_in_parquet': 16}, {'name_in_txt': 'Chapéu Mangueira 1', 'name_in_parquet': 'Chapéu Mangueira 1', 'station_id_in_txt': 81, 'station_id_in_parquet': 17}, {'name_in_txt': 'Piancó 2', 'name_in_parquet': 'Piancó 2', 'station_id_in_txt': 82, 'station_id_in_parquet': 55}, {'name_in_txt': 'Morro da Fé 1', 'name_in_parquet': 'Morro da Fé 1', 'station_id_in_txt': 83, 'station_id_in_parquet': 40}, {'name_in_txt': 'Catumbi 1', 'name_in_parquet': 'Catumbi 1', 'station_id_in_txt': 84, 'station_id_in_parquet': 13}, {'name_in_txt': 'Parque Vila Isabel 2', 'name_in_parquet': 'Parque Vila Isabel 2', 'station_id_in_txt': 85, 'station_id_in_parquet': 53}, {'name_in_txt': 'Vila Cruzeiro 1', 'name_in_parquet': 'Vila Cruzeiro 1', 'station_id_in_txt': 86, 'station_id_in_parquet': 81}, {'name_in_txt': 'Cariri 1', 'name_in_parquet': 'Cariri 1', 'station_id_in_txt': 87, 'station_id_in_parquet': 12}, {'name_in_txt': 'Rua Quiririm 2', 'name_in_parquet': 'Rua Quiririm 2', 'station_id_in_txt': 88, 'station_id_in_parquet': 63}, {'name_in_txt': 'Fazenda Catete 1', 'name_in_parquet': 'Fazenda Catete 1', 'station_id_in_txt': 89, 'station_id_in_parquet': 23}, {'name_in_txt': 'Julio Otoni 1', 'name_in_parquet': 'Julio Otoni 1', 'station_id_in_txt': 9, 'station_id_in_parquet': 31}, {'name_in_txt': 'Santa Marta 1', 'name_in_parquet': 'Santa Marta 1', 'station_id_in_txt': 90, 'station_id_in_parquet': 66}, {'name_in_txt': 'São Carlos 1', 'name_in_parquet': 'São Carlos 1', 'station_id_in_txt': 91, 'station_id_in_parquet': 68}, {'name_in_txt': 'Espírito Santo 1', 'name_in_parquet': 'Espírito Santo 1', 'station_id_in_txt': 92, 'station_id_in_parquet': 22}, {'name_in_txt': 'Ocidental Fallet 1', 'name_in_parquet': 'Ocidental Fallet 1', 'station_id_in_txt': 93, 'station_id_in_parquet': 45}, {'name_in_txt': 'Relicário 1', 'name_in_parquet': 'Relicário 1', 'station_id_in_txt': 94, 'station_id_in_parquet': 57}, {'name_in_txt': 'Nova Brasilia 1', 'name_in_parquet': 'Nova Brasilia 1', 'station_id_in_txt': 95, 'station_id_in_parquet': 43}, {'name_in_txt': 'Santa Alexandrina 1 / Paula Ramos', 'name_in_parquet': 'Santa Alexandrina 1 / Paula Ramos', 'station_id_in_txt': 96, 'station_id_in_parquet': 65}, {'name_in_txt': 'Jardim do Carmo 1', 'name_in_parquet': 'Jardim do Carmo 1', 'station_id_in_txt': 98, 'station_id_in_parquet': 29}, {'name_in_txt': 'Vila Cabuçu 1 / Barro Preto', 'name_in_parquet': 'Vila Cabuçu 1 / Barro Preto', 'station_id_in_txt': 99, 'station_id_in_parquet': 80}]\n",
      "\n",
      "\n",
      "    Stations not found in parquet:\n",
      "    [{'name': 'Travessa Antonina 1', 'station_id': 106}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_stations_not_found_in_parquet(\n",
    "    stations_name_id: list[StationNameId], df_websirenes: pd.DataFrame\n",
    ") -> list[StationNameId]:\n",
    "    not_founds_in_parquet: list[StationNameId] = []\n",
    "    for station_name_id in stations_name_id:\n",
    "        name = station_name_id[\"name\"]\n",
    "        if name in df_websirenes.estacao.values:\n",
    "            continue\n",
    "        not_founds_in_parquet.append(station_name_id)\n",
    "    return not_founds_in_parquet\n",
    "\n",
    "\n",
    "def get_stations_not_matching_id_by_name(\n",
    "    stations_name_id: list[StationNameId], df_websirenes: pd.DataFrame\n",
    ") -> list:\n",
    "    not_matching_id_by_name: list = []\n",
    "    for station_name_id in stations_name_id:\n",
    "        name_in_txt = station_name_id[\"name\"]\n",
    "        station_id_in_txt = station_name_id[\"station_id\"]\n",
    "\n",
    "        if name_in_txt not in df_websirenes.estacao.values:\n",
    "            print(f\"Station {name_in_txt} not found in parquet\")\n",
    "            continue\n",
    "\n",
    "        station = df_websirenes[df_websirenes.estacao == name_in_txt].iloc[0]\n",
    "        name_in_parquet = station[\"estacao\"]\n",
    "        station_id_in_parquet = station[\"id_estacao\"]\n",
    "\n",
    "        if station_id_in_txt == station_id_in_parquet:\n",
    "            continue\n",
    "\n",
    "        not_matching_id_by_name.append(\n",
    "            {\n",
    "                \"name_in_txt\": name_in_txt,\n",
    "                \"name_in_parquet\": name_in_parquet,\n",
    "                \"station_id_in_txt\": station_id_in_txt,\n",
    "                \"station_id_in_parquet\": station_id_in_parquet,\n",
    "            }\n",
    "        )\n",
    "    return not_matching_id_by_name\n",
    "\n",
    "\n",
    "not_matching_id_by_name = get_stations_not_matching_id_by_name(stations_name_id, df_websirenes)\n",
    "print(f\"\"\"\n",
    "    Stations not matching id by name:\n",
    "    {not_matching_id_by_name}\n",
    "\"\"\")\n",
    "\n",
    "assert all([x[\"name_in_txt\"] == x[\"name_in_parquet\"] for x in not_matching_id_by_name])\n",
    "\n",
    "not_founds_in_parquet = get_stations_not_found_in_parquet(stations_name_id, df_websirenes)\n",
    "print(f\"\"\"\n",
    "    Stations not found in parquet:\n",
    "    {not_founds_in_parquet}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/84 [00:03<05:00,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8575_-43.313.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/84 [00:06<04:32,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.914_-43.2822.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 3/84 [00:09<04:20,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9808_-43.1969.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 4/84 [00:12<04:08,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8711_-43.2894.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 5/84 [00:13<02:57,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station Travessa Antonina 1 not found in parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 6/84 [00:16<03:15,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9119_-43.2635.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 7/84 [00:19<03:26,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9327_-43.2567.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 8/84 [00:22<03:32,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8606_-43.3027.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 9/84 [00:25<03:30,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.908_-43.2667.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 10/84 [00:28<03:26,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.875278_-43.305833.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 11/84 [00:31<03:25,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9405_-43.2531.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 12/84 [00:34<03:26,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8598_-43.2795.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 13/84 [00:37<03:32,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9269_-43.1994.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 14/84 [00:40<03:31,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9901_-43.2325.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 15/84 [00:43<03:28,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8547_-43.2725.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 16/84 [00:46<03:35,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9226_-43.2035.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 17/84 [00:49<03:29,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9313_-43.2169.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 18/84 [00:52<03:24,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9647_-43.195.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 19/84 [00:55<03:17,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9797_-43.1914.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 20/84 [00:58<03:13,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9423_-43.2432.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 21/84 [01:01<03:08,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.912_-43.2526.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 22/84 [01:04<03:02,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8443_-43.2905.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 23/84 [01:07<02:59,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9178_-43.2817.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 24/84 [01:10<02:59,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9142_-43.2852.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 25/84 [01:13<02:59,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8766_-43.3011.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 26/84 [01:16<02:53,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9717_-43.3319.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 27/84 [01:19<02:40,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8928_-43.3432.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 28/84 [01:22<02:45,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.934_-43.2032.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 29/84 [01:25<02:46,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9315_-43.2515.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 30/84 [01:28<02:43,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9841_-43.2488.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 31/84 [01:31<02:43,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9333_-43.2611.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 32/84 [01:35<02:47,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8985_-43.2347.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 33/84 [01:38<02:46,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8575_-43.333.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 34/84 [01:42<02:45,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9295_-43.2654.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 35/84 [01:45<02:42,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9122_-43.2038.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 36/84 [01:48<02:34,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9164_-43.3422.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 37/84 [01:51<02:34,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9974_-43.2422.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 38/84 [01:55<02:30,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9324_-43.2012.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 39/84 [01:57<02:21,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9896_-43.2519.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 40/84 [02:00<02:12,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9899_-43.2471.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 41/84 [02:03<02:08,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8636_-43.2636.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 42/84 [02:06<02:05,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8595_-43.2657.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 43/84 [02:09<02:05,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9023_-43.3434.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 44/84 [02:13<02:06,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9911_-43.3114.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 45/84 [02:16<02:03,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9307_-43.1914.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 46/84 [02:20<02:06,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9617_-43.188.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 47/84 [02:23<02:00,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9017_-43.3594.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 48/84 [02:26<01:55,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8344_-43.2953.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 49/84 [02:29<01:51,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9166_-43.2979.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 50/84 [02:33<01:57,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8652_-43.2805.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 51/84 [02:37<01:54,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9135_-43.2942.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 52/84 [02:40<01:47,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8641_-43.283.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 53/84 [02:43<01:43,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9266_-43.218.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 54/84 [02:46<01:41,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9291_-43.2623.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 55/84 [02:50<01:36,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9046_-43.264.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 56/84 [02:53<01:31,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8606_-43.3317.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 57/84 [02:56<01:28,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9056_-43.2341.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 58/84 [02:59<01:23,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9043_-43.2388.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 59/84 [03:03<01:21,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9255_-43.2155.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 60/84 [03:05<01:16,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9302_-43.226.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 61/84 [03:08<01:11,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8683_-43.3133.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 62/84 [03:11<01:07,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8414_-43.2933.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 63/84 [03:14<01:04,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9447_-43.208.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 64/84 [03:18<01:02,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8633_-43.3111.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 65/84 [03:21<00:59,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9263_-43.2196.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 66/84 [03:24<00:57,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9605_-43.1679.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 67/84 [03:27<00:53,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8651_-43.2586.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 68/84 [03:30<00:49,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8456_-43.2978.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 69/84 [03:33<00:46,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9214_-43.1967.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 70/84 [03:37<00:45,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9159_-43.2591.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 71/84 [03:40<00:43,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8522_-43.2783.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 72/84 [03:43<00:38,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8483_-43.2805.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 73/84 [03:46<00:34,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8886_-43.3569.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 74/84 [03:49<00:31,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.925_-43.1825.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 75/84 [03:52<00:27,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9336_-43.1939.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 76/84 [03:55<00:24,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9478_-43.1936.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 77/84 [03:59<00:22,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9181_-43.2008.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 78/84 [04:02<00:18,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.89_-43.3439.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 79/84 [04:05<00:15,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9262_-43.1918.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 80/84 [04:08<00:12,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.86_-43.2864.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 81/84 [04:11<00:09,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8645_-43.2756.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 82/84 [04:15<00:06,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9357_-43.2127.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 83/84 [04:18<00:03,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.8514_-43.3045.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [04:22<00:00,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -22.9147_-43.2757.parquet already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class WebSirenesBuilder:\n",
    "    def __init__(self) -> None:\n",
    "        self.websirenes_datasets_path = Path(\"./websirenes_datasets\")\n",
    "        if not self.websirenes_datasets_path.exists():\n",
    "            self.websirenes_datasets_path.mkdir()\n",
    "\n",
    "    def merge_by_name(\n",
    "        self, df_websirenes: pd.DataFrame, df_websirenes_defesa_civil: pd.DataFrame\n",
    "    ) -> pd.DataFrame:\n",
    "        df_websirenes_defesa_civil.reset_index(inplace=True)\n",
    "        df = pd.merge(\n",
    "            df_websirenes,\n",
    "            df_websirenes_defesa_civil,\n",
    "            left_on=\"estacao\",\n",
    "            right_on=\"nome\",\n",
    "            how=\"inner\",\n",
    "        )\n",
    "        df.drop(columns=[\"estacao\", \"id_estacao\"], inplace=True)\n",
    "        df.set_index(\"horaLeitura\", inplace=True)\n",
    "        return df\n",
    "\n",
    "    def create_key(self, df: pd.DataFrame) -> str:\n",
    "        row = df.iloc[0]\n",
    "        return f\"{row['latitude']}_{row['longitude']}\"\n",
    "\n",
    "    def write_dataset(self, df: pd.DataFrame, key: str):\n",
    "        if not self.websirenes_datasets_path.exists():\n",
    "            self.websirenes_datasets_path.mkdir()\n",
    "        if (self.websirenes_datasets_path / f\"{key}.parquet\").exists():\n",
    "            print(f\"Dataset {key}.parquet already exists\")\n",
    "            return\n",
    "        df.to_parquet(self.websirenes_datasets_path / f\"{key}.parquet\")\n",
    "\n",
    "\n",
    "websirenes_builder = WebSirenesBuilder()\n",
    "\n",
    "\n",
    "def build_websirenes_datasets():\n",
    "    files = websirenes_parser.list_files()\n",
    "\n",
    "    for file in tqdm(files):\n",
    "        df = websirenes_parser.get_dataframe(os.path.join(\"websirenes_defesa_civil\", file))\n",
    "\n",
    "        station_name = df[WebSireneSchema.nome].iloc[0]\n",
    "        if station_name in [x[\"name\"] for x in not_founds_in_parquet]:\n",
    "            print(f\"Station {station_name} not found in parquet\")\n",
    "            continue\n",
    "\n",
    "        if df.index.min() < websirenes_parser.minimum_date:\n",
    "            websirenes_parser.minimum_date = df.index.min()\n",
    "        if df.index.max() > websirenes_parser.maximum_date:\n",
    "            websirenes_parser.maximum_date = df.index.max()\n",
    "\n",
    "        websirenes_parser.assert_is_sorted_by_date(df)\n",
    "        df = websirenes_builder.merge_by_name(df_websirenes, df)\n",
    "        key = websirenes_builder.create_key(df)\n",
    "        websirenes_builder.write_dataset(df, key)\n",
    "        # print(f\"\"\"\n",
    "        #     Initial operation date: {df.index[0]}\n",
    "        #     Last operation date: {df.index[-1]}\n",
    "        #     Last operation date using max: {df.index.max()}\n",
    "        #     Station name: {df.nome.iloc[0]}\n",
    "        #     Station key: {key}\n",
    "        # \"\"\")\n",
    "\n",
    "\n",
    "build_websirenes_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2011-04-12 20:30:00'), Timestamp('2022-06-02 21:30:00'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "websirenes_parser.minimum_date, websirenes_parser.maximum_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Timestamp('2011-04-12 20:00:00')\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_string = \"2011-04-12-20\"  # build a pd.Timestamp Timestamp('2011-04-12 20:00:00')\n",
    "date = pd.Timestamp(date_string, tz=None)\n",
    "repr(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Path.glob at 0x7f47f6b36eb0>\n",
      "['-22.8344_-43.2953', '-22.8414_-43.2933', '-22.8443_-43.2905', '-22.8456_-43.2978', '-22.8483_-43.2805', '-22.8514_-43.3045', '-22.8522_-43.2783', '-22.8547_-43.2725', '-22.8575_-43.313', '-22.8575_-43.333', '-22.8595_-43.2657', '-22.8598_-43.2795', '-22.8606_-43.3027', '-22.8606_-43.3317', '-22.8633_-43.3111', '-22.8636_-43.2636', '-22.8641_-43.283', '-22.8645_-43.2756', '-22.8651_-43.2586', '-22.8652_-43.2805', '-22.8683_-43.3133', '-22.86_-43.2864', '-22.8711_-43.2894', '-22.875278_-43.305833', '-22.8766_-43.3011', '-22.8886_-43.3569', '-22.8928_-43.3432', '-22.8985_-43.2347', '-22.89_-43.3439', '-22.9017_-43.3594', '-22.9023_-43.3434', '-22.9043_-43.2388', '-22.9046_-43.264', '-22.9056_-43.2341', '-22.908_-43.2667', '-22.9119_-43.2635', '-22.9122_-43.2038', '-22.912_-43.2526', '-22.9135_-43.2942', '-22.9142_-43.2852', '-22.9147_-43.2757', '-22.914_-43.2822', '-22.9159_-43.2591', '-22.9164_-43.3422', '-22.9166_-43.2979', '-22.9178_-43.2817', '-22.9181_-43.2008', '-22.9214_-43.1967', '-22.9226_-43.2035', '-22.9255_-43.2155', '-22.925_-43.1825', '-22.9262_-43.1918', '-22.9263_-43.2196', '-22.9266_-43.218', '-22.9269_-43.1994', '-22.9291_-43.2623', '-22.9295_-43.2654', '-22.9302_-43.226', '-22.9307_-43.1914', '-22.9313_-43.2169', '-22.9315_-43.2515', '-22.9324_-43.2012', '-22.9327_-43.2567', '-22.9333_-43.2611', '-22.9336_-43.1939', '-22.934_-43.2032', '-22.9357_-43.2127', '-22.9405_-43.2531', '-22.9423_-43.2432', '-22.9447_-43.208', '-22.9478_-43.1936', '-22.9605_-43.1679', '-22.9617_-43.188', '-22.9647_-43.195', '-22.9717_-43.3319', '-22.9797_-43.1914', '-22.9808_-43.1969', '-22.9841_-43.2488', '-22.9896_-43.2519', '-22.9899_-43.2471', '-22.9901_-43.2325', '-22.9911_-43.3114', '-22.9974_-43.2422']\n",
      "          horaLeitura  latitude longitude                     nome  m15  m30  \\\n",
      "0 2012-05-21 20:45:00  -22.8344  -43.2953  Guaíba 1 / Vila Pequiri  NaN  NaN   \n",
      "1 2012-05-21 21:00:00  -22.8344  -43.2953  Guaíba 1 / Vila Pequiri  0.0  NaN   \n",
      "2 2012-05-21 21:15:00  -22.8344  -43.2953  Guaíba 1 / Vila Pequiri  0.0  NaN   \n",
      "3 2012-05-21 21:30:00  -22.8344  -43.2953  Guaíba 1 / Vila Pequiri  0.0  NaN   \n",
      "4 2012-05-21 21:45:00  -22.8344  -43.2953  Guaíba 1 / Vila Pequiri  0.0  NaN   \n",
      "\n",
      "   h01  h02  h03  h04  h24  h96  station_id  \n",
      "0  NaN  NaN  NaN  NaN  NaN  NaN          35  \n",
      "1  NaN  NaN  NaN  NaN  NaN  NaN          35  \n",
      "2  NaN  NaN  NaN  NaN  NaN  NaN          35  \n",
      "3  NaN  NaN  NaN  NaN  NaN  NaN          35  \n",
      "4  NaN  NaN  NaN  NaN  NaN  NaN          35  \n"
     ]
    }
   ],
   "source": [
    "def load_websirene_dataset(key: str) -> pd.DataFrame:\n",
    "    return pd.read_parquet(f\"./websirenes_datasets/{key}.parquet\")\n",
    "\n",
    "\n",
    "print(Path(\"./websirenes_datasets\").glob(\"*.parquet\"))\n",
    "\n",
    "keys = [x.stem for x in Path(\"./websirenes_datasets\").glob(\"*.parquet\")]\n",
    "print(keys)\n",
    "\n",
    "df_example = load_websirene_dataset(keys[0])\n",
    "df_example.reset_index(inplace=True)\n",
    "print(df_example.head())\n",
    "\n",
    "assert all(df_example.latitude == df_example.latitude.iloc[0])\n",
    "assert all(df_example.longitude == df_example.longitude.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horaLeitura</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>nome</th>\n",
       "      <th>m15</th>\n",
       "      <th>m30</th>\n",
       "      <th>h01</th>\n",
       "      <th>h02</th>\n",
       "      <th>h03</th>\n",
       "      <th>h04</th>\n",
       "      <th>h24</th>\n",
       "      <th>h96</th>\n",
       "      <th>station_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-05-21 20:45:00</td>\n",
       "      <td>-22.8344</td>\n",
       "      <td>-43.2953</td>\n",
       "      <td>Guaíba 1 / Vila Pequiri</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-05-21 21:00:00</td>\n",
       "      <td>-22.8344</td>\n",
       "      <td>-43.2953</td>\n",
       "      <td>Guaíba 1 / Vila Pequiri</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-05-21 21:15:00</td>\n",
       "      <td>-22.8344</td>\n",
       "      <td>-43.2953</td>\n",
       "      <td>Guaíba 1 / Vila Pequiri</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-05-21 21:30:00</td>\n",
       "      <td>-22.8344</td>\n",
       "      <td>-43.2953</td>\n",
       "      <td>Guaíba 1 / Vila Pequiri</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-05-21 21:45:00</td>\n",
       "      <td>-22.8344</td>\n",
       "      <td>-43.2953</td>\n",
       "      <td>Guaíba 1 / Vila Pequiri</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344071</th>\n",
       "      <td>2022-06-02 20:15:00</td>\n",
       "      <td>-22.8344</td>\n",
       "      <td>-43.2953</td>\n",
       "      <td>Guaíba 1 / Vila Pequiri</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344072</th>\n",
       "      <td>2022-06-02 20:30:00</td>\n",
       "      <td>-22.8344</td>\n",
       "      <td>-43.2953</td>\n",
       "      <td>Guaíba 1 / Vila Pequiri</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344073</th>\n",
       "      <td>2022-06-02 20:45:00</td>\n",
       "      <td>-22.8344</td>\n",
       "      <td>-43.2953</td>\n",
       "      <td>Guaíba 1 / Vila Pequiri</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344074</th>\n",
       "      <td>2022-06-02 21:00:00</td>\n",
       "      <td>-22.8344</td>\n",
       "      <td>-43.2953</td>\n",
       "      <td>Guaíba 1 / Vila Pequiri</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344075</th>\n",
       "      <td>2022-06-02 21:15:00</td>\n",
       "      <td>-22.8344</td>\n",
       "      <td>-43.2953</td>\n",
       "      <td>Guaíba 1 / Vila Pequiri</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344076 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               horaLeitura  latitude longitude                     nome  m15  \\\n",
       "0      2012-05-21 20:45:00  -22.8344  -43.2953  Guaíba 1 / Vila Pequiri  NaN   \n",
       "1      2012-05-21 21:00:00  -22.8344  -43.2953  Guaíba 1 / Vila Pequiri  0.0   \n",
       "2      2012-05-21 21:15:00  -22.8344  -43.2953  Guaíba 1 / Vila Pequiri  0.0   \n",
       "3      2012-05-21 21:30:00  -22.8344  -43.2953  Guaíba 1 / Vila Pequiri  0.0   \n",
       "4      2012-05-21 21:45:00  -22.8344  -43.2953  Guaíba 1 / Vila Pequiri  0.0   \n",
       "...                    ...       ...       ...                      ...  ...   \n",
       "344071 2022-06-02 20:15:00  -22.8344  -43.2953  Guaíba 1 / Vila Pequiri  0.0   \n",
       "344072 2022-06-02 20:30:00  -22.8344  -43.2953  Guaíba 1 / Vila Pequiri  0.0   \n",
       "344073 2022-06-02 20:45:00  -22.8344  -43.2953  Guaíba 1 / Vila Pequiri  0.0   \n",
       "344074 2022-06-02 21:00:00  -22.8344  -43.2953  Guaíba 1 / Vila Pequiri  0.0   \n",
       "344075 2022-06-02 21:15:00  -22.8344  -43.2953  Guaíba 1 / Vila Pequiri  0.0   \n",
       "\n",
       "        m30  h01  h02  h03  h04  h24  h96  station_id  \n",
       "0       NaN  NaN  NaN  NaN  NaN  NaN  NaN          35  \n",
       "1       NaN  NaN  NaN  NaN  NaN  NaN  NaN          35  \n",
       "2       NaN  NaN  NaN  NaN  NaN  NaN  NaN          35  \n",
       "3       NaN  NaN  NaN  NaN  NaN  NaN  NaN          35  \n",
       "4       NaN  NaN  NaN  NaN  NaN  NaN  NaN          35  \n",
       "...     ...  ...  ...  ...  ...  ...  ...         ...  \n",
       "344071  0.0  0.0  0.0  0.0  0.0  0.0  0.0          35  \n",
       "344072  0.0  0.0  0.0  0.0  0.0  0.0  0.0          35  \n",
       "344073  0.0  0.0  0.0  0.0  0.0  0.0  0.0          35  \n",
       "344074  0.0  0.0  0.0  0.0  0.0  0.0  0.0          35  \n",
       "344075  0.0  0.0  0.0  0.0  0.0  0.0  0.0          35  \n",
       "\n",
       "[344076 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mabordagem correta, pegar as medidas do passado para montar o de 15:00h\u001b[0m\n",
      "                     precipitation\n",
      "2022-01-09 15:00:00       0.374540\n",
      "2022-01-09 15:15:00       0.950714\n",
      "2022-01-09 15:30:00       0.731994\n",
      "2022-01-09 15:45:00       0.598658\n",
      "2022-01-09 16:00:00       0.156019\n",
      "2022-01-09 16:15:00       0.155995\n",
      "2022-01-09 16:30:00       0.058084\n",
      "2022-01-09 16:45:00       0.866176\n",
      "2022-01-09 17:00:00       0.601115\n",
      "                     precipitation\n",
      "2022-01-09 15:00:00       0.374540\n",
      "2022-01-09 16:00:00       2.437385\n",
      "2022-01-09 17:00:00       1.681369\n",
      "0.37454\n",
      "2.437385\n",
      "1.681369\n"
     ]
    }
   ],
   "source": [
    "green_color_terminal = \"\\033[92m\"\n",
    "reset_color_terminal = \"\\033[0m\"\n",
    "print(\n",
    "    f\"{green_color_terminal}abordagem correta, pegar as medidas do passado para montar o de 15:00h{reset_color_terminal}\"\n",
    ")\n",
    "\n",
    "timestamps = pd.date_range(start=\"2022-01-09 15:00:00\", end=\"2022-01-09 17:00:00\", freq=\"15min\")\n",
    "\n",
    "df_example2 = pd.DataFrame(index=timestamps)\n",
    "\n",
    "df_example2[\"precipitation\"] = np.random.rand(len(df_example2))\n",
    "\n",
    "print(df_example2)\n",
    "\n",
    "df_example2_resampled = df_example2.resample(\"1h\", closed=\"right\", label=\"right\").sum()\n",
    "print(df_example2_resampled)\n",
    "\n",
    "dalezada = df_example2[\n",
    "    (df_example2.index >= \"2022-01-09 14:15:00\") & (df_example2.index <= \"2022-01-09 15:00:00\")\n",
    "]\n",
    "print(round(dalezada[\"precipitation\"].sum(), 6))\n",
    "\n",
    "dalezada = df_example2[\n",
    "    (df_example2.index >= \"2022-01-09 15:15:00\") & (df_example2.index <= \"2022-01-09 16:00:00\")\n",
    "]\n",
    "print(round(dalezada[\"precipitation\"].sum(), 6))\n",
    "dalezada = df_example2[\n",
    "    (df_example2.index >= \"2022-01-09 16:15:00\") & (df_example2.index <= \"2022-01-09 17:00:00\")\n",
    "]\n",
    "print(round(dalezada[\"precipitation\"].sum(), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "7.0\n",
      "0.0\n",
      "True\n",
      "False\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"A\": [1, 2, np.nan, 4],\n",
    "    \"B\": [5, np.nan, 7, 8],\n",
    "    \"C\": [np.nan, 10, 11, 12],\n",
    "    \"D\": [np.nan, np.nan, np.nan, np.nan],\n",
    "}\n",
    "df_with_nan = pd.DataFrame(data)\n",
    "a_values = df_with_nan[\"A\"]\n",
    "print(a_values.isnull().any())\n",
    "print(a_values.isnull().all())\n",
    "print(a_values.sum())\n",
    "print(df_with_nan[\"D\"].sum())\n",
    "print(df_with_nan[\"D\"].isnull().all())\n",
    "print(df_with_nan[\"C\"].isnull().all())\n",
    "print(max([np.nan, np.nan]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2022-06-02 21:15:00')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_example.horaLeitura.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.date'>\n",
      "0.2\n",
      "2022-01-09 17:00:00\n",
      "2022-01-09 16:15:00\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horaLeitura</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>nome</th>\n",
       "      <th>m15</th>\n",
       "      <th>m30</th>\n",
       "      <th>h01</th>\n",
       "      <th>h02</th>\n",
       "      <th>h03</th>\n",
       "      <th>h04</th>\n",
       "      <th>h24</th>\n",
       "      <th>h96</th>\n",
       "      <th>station_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>330647</th>\n",
       "      <td>2022-01-09 16:15:00</td>\n",
       "      <td>-22.8344</td>\n",
       "      <td>-43.2953</td>\n",
       "      <td>Guaíba 1 / Vila Pequiri</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>50.8</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330648</th>\n",
       "      <td>2022-01-09 16:30:00</td>\n",
       "      <td>-22.8344</td>\n",
       "      <td>-43.2953</td>\n",
       "      <td>Guaíba 1 / Vila Pequiri</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>50.8</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330649</th>\n",
       "      <td>2022-01-09 16:45:00</td>\n",
       "      <td>-22.8344</td>\n",
       "      <td>-43.2953</td>\n",
       "      <td>Guaíba 1 / Vila Pequiri</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>50.8</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330650</th>\n",
       "      <td>2022-01-09 17:00:00</td>\n",
       "      <td>-22.8344</td>\n",
       "      <td>-43.2953</td>\n",
       "      <td>Guaíba 1 / Vila Pequiri</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>50.8</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               horaLeitura  latitude longitude                     nome  m15  \\\n",
       "330647 2022-01-09 16:15:00  -22.8344  -43.2953  Guaíba 1 / Vila Pequiri  0.0   \n",
       "330648 2022-01-09 16:30:00  -22.8344  -43.2953  Guaíba 1 / Vila Pequiri  0.0   \n",
       "330649 2022-01-09 16:45:00  -22.8344  -43.2953  Guaíba 1 / Vila Pequiri  0.0   \n",
       "330650 2022-01-09 17:00:00  -22.8344  -43.2953  Guaíba 1 / Vila Pequiri  0.0   \n",
       "\n",
       "        m30  h01  h02  h03  h04  h24   h96  station_id  \n",
       "330647  0.0  0.0  0.0  0.0  0.0  6.0  50.8          35  \n",
       "330648  0.0  0.0  0.0  0.0  0.0  5.8  50.8          35  \n",
       "330649  0.0  0.0  0.0  0.0  0.0  5.8  50.8          35  \n",
       "330650  0.0  0.0  0.0  0.0  0.0  5.8  50.8          35  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(df_example.horaLeitura.dt.date[0]))\n",
    "\n",
    "# dalezada = df_example[\n",
    "#     (df_example.horaLeitura >= '2022-01-09 14:00:00-03') & (df_example.horaLeitura <= '2022-01-09 15:00:00-03')\n",
    "# ]\n",
    "\n",
    "# start_date = datetime.strptime('2022-01-09 14:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "# end_date = datetime.strptime('2022-01-09 15:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "start_date = pd.to_datetime(\n",
    "    datetime.strptime(\"2022-01-09 14:00:00-03:00\", \"%Y-%m-%d %H:%M:%S%z\")\n",
    ").tz_convert(None)\n",
    "end_date = pd.to_datetime(\n",
    "    datetime.strptime(\"2022-01-09 15:00:00-03:00\", \"%Y-%m-%d %H:%M:%S%z\")\n",
    ").tz_convert(None)\n",
    "\n",
    "dalezada = df_example[(df_example.horaLeitura >= start_date) & (df_example.horaLeitura <= end_date)]\n",
    "m15_values = dalezada[\"m15\"].values\n",
    "print(m15_values.sum())\n",
    "\n",
    "\n",
    "current_date = pd.to_datetime(\n",
    "    datetime.strptime(\"2022-01-09 14:00:00-03:00\", \"%Y-%m-%d %H:%M:%S%z\")\n",
    ").tz_convert(None)\n",
    "new_date = current_date - timedelta(minutes=45)\n",
    "print(current_date)\n",
    "print(new_date)\n",
    "\n",
    "dalezada = df_example[\n",
    "    (df_example.horaLeitura >= str(new_date)) & (df_example.horaLeitura <= str(current_date))\n",
    "]\n",
    "\n",
    "m15_values = dalezada[\"m15\"].values\n",
    "print(m15_values.sum())\n",
    "dalezada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt; Size: 8MB\n",
       "Dimensions:    (time: 744, latitude: 11, longitude: 21)\n",
       "Coordinates:\n",
       "  * longitude  (longitude) float32 84B -44.0 -43.9 -43.8 ... -42.2 -42.1 -42.0\n",
       "  * latitude   (latitude) float32 44B -22.0 -22.1 -22.2 ... -22.8 -22.9 -23.0\n",
       "  * time       (time) datetime64[ns] 6kB 2023-01-01 ... 2023-01-31T23:00:00\n",
       "Data variables:\n",
       "    u10        (time, latitude, longitude) float64 1MB ...\n",
       "    v10        (time, latitude, longitude) float64 1MB ...\n",
       "    d2m        (time, latitude, longitude) float64 1MB ...\n",
       "    t2m        (time, latitude, longitude) float64 1MB ...\n",
       "    sp         (time, latitude, longitude) float64 1MB ...\n",
       "    tp         (time, latitude, longitude) float64 1MB ...\n",
       "Attributes:\n",
       "    Conventions:  CF-1.6\n",
       "    history:      2024-05-14 22:57:34 GMT by grib_to_netcdf-2.28.1: /opt/ecmw...</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-671bff0c-fd69-4105-b6fa-5fe9b9e7db5b' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-671bff0c-fd69-4105-b6fa-5fe9b9e7db5b' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 744</li><li><span class='xr-has-index'>latitude</span>: 11</li><li><span class='xr-has-index'>longitude</span>: 21</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-e13f022e-1a3e-4a1c-8bd2-adaad4199950' class='xr-section-summary-in' type='checkbox'  checked><label for='section-e13f022e-1a3e-4a1c-8bd2-adaad4199950' class='xr-section-summary' >Coordinates: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>longitude</span></div><div class='xr-var-dims'>(longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>-44.0 -43.9 -43.8 ... -42.1 -42.0</div><input id='attrs-cd5bf33a-c72c-4e19-86a2-1571f43eaa08' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-cd5bf33a-c72c-4e19-86a2-1571f43eaa08' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-3344b61c-1bf6-41d4-a069-50c59edfe174' class='xr-var-data-in' type='checkbox'><label for='data-3344b61c-1bf6-41d4-a069-50c59edfe174' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>long_name :</span></dt><dd>longitude</dd></dl></div><div class='xr-var-data'><pre>array([-44. , -43.9, -43.8, -43.7, -43.6, -43.5, -43.4, -43.3, -43.2, -43.1,\n",
       "       -43. , -42.9, -42.8, -42.7, -42.6, -42.5, -42.4, -42.3, -42.2, -42.1,\n",
       "       -42. ], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>latitude</span></div><div class='xr-var-dims'>(latitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>-22.0 -22.1 -22.2 ... -22.9 -23.0</div><input id='attrs-a3562ede-0a63-412b-bae3-16181fdea0ab' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-a3562ede-0a63-412b-bae3-16181fdea0ab' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-6fc81a8f-d0fe-4b72-929d-948abfbbacbc' class='xr-var-data-in' type='checkbox'><label for='data-6fc81a8f-d0fe-4b72-929d-948abfbbacbc' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>long_name :</span></dt><dd>latitude</dd></dl></div><div class='xr-var-data'><pre>array([-22. , -22.1, -22.2, -22.3, -22.4, -22.5, -22.6, -22.7, -22.8, -22.9,\n",
       "       -23. ], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2023-01-01 ... 2023-01-31T23:00:00</div><input id='attrs-d421ade2-a0b8-440d-9109-19e57c5d2880' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-d421ade2-a0b8-440d-9109-19e57c5d2880' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e7811e9d-832b-4549-abde-ab93a936cbe0' class='xr-var-data-in' type='checkbox'><label for='data-e7811e9d-832b-4549-abde-ab93a936cbe0' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>time</dd></dl></div><div class='xr-var-data'><pre>array([&#x27;2023-01-01T00:00:00.000000000&#x27;, &#x27;2023-01-01T01:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-01T02:00:00.000000000&#x27;, ..., &#x27;2023-01-31T21:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-31T22:00:00.000000000&#x27;, &#x27;2023-01-31T23:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-7c5db10a-1c94-4fae-a86b-ee73112fc50f' class='xr-section-summary-in' type='checkbox'  checked><label for='section-7c5db10a-1c94-4fae-a86b-ee73112fc50f' class='xr-section-summary' >Data variables: <span>(6)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>u10</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-3fc7d7e0-fe90-41da-ae5f-6bbd941f9a40' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-3fc7d7e0-fe90-41da-ae5f-6bbd941f9a40' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-8e78eeb5-380d-40e1-8973-270d85d7536b' class='xr-var-data-in' type='checkbox'><label for='data-8e78eeb5-380d-40e1-8973-270d85d7536b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>m s**-1</dd><dt><span>long_name :</span></dt><dd>10 metre U wind component</dd></dl></div><div class='xr-var-data'><pre>[171864 values with dtype=float64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>v10</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-1b41606c-d911-4893-b14f-0c4ba3547f02' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-1b41606c-d911-4893-b14f-0c4ba3547f02' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-57587703-5646-4a82-9209-2481a0a14274' class='xr-var-data-in' type='checkbox'><label for='data-57587703-5646-4a82-9209-2481a0a14274' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>m s**-1</dd><dt><span>long_name :</span></dt><dd>10 metre V wind component</dd></dl></div><div class='xr-var-data'><pre>[171864 values with dtype=float64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>d2m</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-e21beb63-8eea-4fb2-ae6a-1700f42f2e69' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-e21beb63-8eea-4fb2-ae6a-1700f42f2e69' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ca35d5ca-91c1-4d43-977d-bc96f49ae78a' class='xr-var-data-in' type='checkbox'><label for='data-ca35d5ca-91c1-4d43-977d-bc96f49ae78a' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>K</dd><dt><span>long_name :</span></dt><dd>2 metre dewpoint temperature</dd></dl></div><div class='xr-var-data'><pre>[171864 values with dtype=float64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>t2m</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-18ef5b56-2f10-47bd-ade7-a00eeaa31300' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-18ef5b56-2f10-47bd-ade7-a00eeaa31300' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-cf48f59b-f01b-4c31-b8a6-dc95027ba028' class='xr-var-data-in' type='checkbox'><label for='data-cf48f59b-f01b-4c31-b8a6-dc95027ba028' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>K</dd><dt><span>long_name :</span></dt><dd>2 metre temperature</dd></dl></div><div class='xr-var-data'><pre>[171864 values with dtype=float64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>sp</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-fe48996e-1074-4a85-be11-4f95a1582686' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-fe48996e-1074-4a85-be11-4f95a1582686' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-6808d973-1cb6-4cac-aa0d-c02eda28cc2e' class='xr-var-data-in' type='checkbox'><label for='data-6808d973-1cb6-4cac-aa0d-c02eda28cc2e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>Pa</dd><dt><span>long_name :</span></dt><dd>Surface pressure</dd><dt><span>standard_name :</span></dt><dd>surface_air_pressure</dd></dl></div><div class='xr-var-data'><pre>[171864 values with dtype=float64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>tp</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-3e4e495a-b917-4ec0-945f-1236bc4b13fd' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-3e4e495a-b917-4ec0-945f-1236bc4b13fd' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ef006646-5fa6-436a-b6b6-43444943d54b' class='xr-var-data-in' type='checkbox'><label for='data-ef006646-5fa6-436a-b6b6-43444943d54b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>m</dd><dt><span>long_name :</span></dt><dd>Total precipitation</dd></dl></div><div class='xr-var-data'><pre>[171864 values with dtype=float64]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-d0e8479e-45bf-4886-887d-d7e813d17fd9' class='xr-section-summary-in' type='checkbox'  ><label for='section-d0e8479e-45bf-4886-887d-d7e813d17fd9' class='xr-section-summary' >Indexes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>longitude</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-6a64c712-ff6c-4e35-89e9-efa7ed4e9dfc' class='xr-index-data-in' type='checkbox'/><label for='index-6a64c712-ff6c-4e35-89e9-efa7ed4e9dfc' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([              -44.0, -43.900001525878906,  -43.79999923706055,\n",
       "        -43.70000076293945, -43.599998474121094,               -43.5,\n",
       "       -43.400001525878906,  -43.29999923706055,  -43.20000076293945,\n",
       "       -43.099998474121094,               -43.0, -42.900001525878906,\n",
       "        -42.79999923706055,  -42.70000076293945, -42.599998474121094,\n",
       "                     -42.5, -42.400001525878906,  -42.29999923706055,\n",
       "        -42.20000076293945, -42.099998474121094,               -42.0],\n",
       "      dtype=&#x27;float32&#x27;, name=&#x27;longitude&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>latitude</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-b3e0e2cc-6079-487f-a18a-1b5cf909beee' class='xr-index-data-in' type='checkbox'/><label for='index-b3e0e2cc-6079-487f-a18a-1b5cf909beee' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([              -22.0, -22.100000381469727, -22.200000762939453,\n",
       "       -22.299999237060547, -22.399999618530273,               -22.5,\n",
       "       -22.600000381469727, -22.700000762939453, -22.799999237060547,\n",
       "       -22.899999618530273,               -23.0],\n",
       "      dtype=&#x27;float32&#x27;, name=&#x27;latitude&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-497519ba-ec83-4f3c-860d-4260ed8b18aa' class='xr-index-data-in' type='checkbox'/><label for='index-497519ba-ec83-4f3c-860d-4260ed8b18aa' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2023-01-01 00:00:00&#x27;, &#x27;2023-01-01 01:00:00&#x27;,\n",
       "               &#x27;2023-01-01 02:00:00&#x27;, &#x27;2023-01-01 03:00:00&#x27;,\n",
       "               &#x27;2023-01-01 04:00:00&#x27;, &#x27;2023-01-01 05:00:00&#x27;,\n",
       "               &#x27;2023-01-01 06:00:00&#x27;, &#x27;2023-01-01 07:00:00&#x27;,\n",
       "               &#x27;2023-01-01 08:00:00&#x27;, &#x27;2023-01-01 09:00:00&#x27;,\n",
       "               ...\n",
       "               &#x27;2023-01-31 14:00:00&#x27;, &#x27;2023-01-31 15:00:00&#x27;,\n",
       "               &#x27;2023-01-31 16:00:00&#x27;, &#x27;2023-01-31 17:00:00&#x27;,\n",
       "               &#x27;2023-01-31 18:00:00&#x27;, &#x27;2023-01-31 19:00:00&#x27;,\n",
       "               &#x27;2023-01-31 20:00:00&#x27;, &#x27;2023-01-31 21:00:00&#x27;,\n",
       "               &#x27;2023-01-31 22:00:00&#x27;, &#x27;2023-01-31 23:00:00&#x27;],\n",
       "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;time&#x27;, length=744, freq=None))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-8e2b4a48-9131-4300-b3eb-e6a03cc8a3cc' class='xr-section-summary-in' type='checkbox'  checked><label for='section-8e2b4a48-9131-4300-b3eb-e6a03cc8a3cc' class='xr-section-summary' >Attributes: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>Conventions :</span></dt><dd>CF-1.6</dd><dt><span>history :</span></dt><dd>2024-05-14 22:57:34 GMT by grib_to_netcdf-2.28.1: /opt/ecmwf/mars-client/bin/grib_to_netcdf -S param -o /cache/data9/adaptor.mars.internal-1715727447.0335772-3538-17-4fd0fd8b-6cbd-4465-949a-7ae25c73fad9.nc /cache/tmp/4fd0fd8b-6cbd-4465-949a-7ae25c73fad9-adaptor.mars.internal-1715727095.6959558-3538-6-tmp.grib</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset> Size: 8MB\n",
       "Dimensions:    (time: 744, latitude: 11, longitude: 21)\n",
       "Coordinates:\n",
       "  * longitude  (longitude) float32 84B -44.0 -43.9 -43.8 ... -42.2 -42.1 -42.0\n",
       "  * latitude   (latitude) float32 44B -22.0 -22.1 -22.2 ... -22.8 -22.9 -23.0\n",
       "  * time       (time) datetime64[ns] 6kB 2023-01-01 ... 2023-01-31T23:00:00\n",
       "Data variables:\n",
       "    u10        (time, latitude, longitude) float64 1MB ...\n",
       "    v10        (time, latitude, longitude) float64 1MB ...\n",
       "    d2m        (time, latitude, longitude) float64 1MB ...\n",
       "    t2m        (time, latitude, longitude) float64 1MB ...\n",
       "    sp         (time, latitude, longitude) float64 1MB ...\n",
       "    tp         (time, latitude, longitude) float64 1MB ...\n",
       "Attributes:\n",
       "    Conventions:  CF-1.6\n",
       "    history:      2024-05-14 22:57:34 GMT by grib_to_netcdf-2.28.1: /opt/ecmw..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = (\n",
    "    \"./adaptor.mars.internal-1715727447.0335772-3538-17-4fd0fd8b-6cbd-4465-949a-7ae25c73fad9.nc\"\n",
    ")\n",
    "ds = xr.open_dataset(filename)\n",
    "if \"expver\" in list(ds.coords.keys()):\n",
    "    print(\">>>Oops! expver dimension found. Going to remove it.<<<\")\n",
    "    ds_combine = ds.sel(expver=1).combine_first(ds.sel(expver=5))\n",
    "    ds_combine.load()\n",
    "    ds = ds_combine\n",
    "ds = ds[[\"u10\", \"v10\", \"d2m\", \"t2m\", \"sp\", \"tp\"]]\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   latitude  longitude       u10       v10         d2m         t2m  \\\n",
      "0     -22.0 -44.000000  0.563038 -1.104868  291.277377  294.777236   \n",
      "1     -22.0 -43.900002  0.478085 -0.925669  291.482460  295.077731   \n",
      "2     -22.0 -43.799999  0.336979 -0.871397  291.707201  295.388566   \n",
      "3     -22.0 -43.700001  0.106079 -0.971544  291.875198  295.599235   \n",
      "4     -22.0 -43.599998 -0.123369 -1.100977  292.015718  295.712648   \n",
      "\n",
      "             sp        tp                 time  \n",
      "0  90882.795613  0.003355  2023-01-09 15:00:00  \n",
      "1  91509.727846  0.003943  2023-01-09 15:00:00  \n",
      "2  92337.726202  0.004726  2023-01-09 15:00:00  \n",
      "3  93143.781930  0.005202  2023-01-09 15:00:00  \n",
      "4  93648.910186  0.005397  2023-01-09 15:00:00  \n",
      "<class 'str'>\n",
      "231\n",
      "231\n",
      "latitude type: <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "lats = ds.coords[\"latitude\"].values\n",
    "lons = ds.coords[\"longitude\"].values\n",
    "\n",
    "xd = ds.sel(time=\"2023-01-09T15:00:00.000000000\", method=\"nearest\")\n",
    "df_era5land = xd.to_dataframe()\n",
    "df_era5land.reset_index(inplace=True)\n",
    "df_era5land[\"time\"] = df_era5land[\"time\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(df_era5land.head(5))\n",
    "print(type(df_era5land[\"time\"][0]))\n",
    "df_era5land[\"time\"] = pd.to_datetime(df_era5land[\"time\"])\n",
    "df_era5land.head(26)\n",
    "print(len(df_era5land))\n",
    "print(lats.size * lons.size)\n",
    "assert (\n",
    "    len(df_era5land) == lats.size * lons.size\n",
    "), f\"Expected {lats.size * lons.size} got {len(df_era5land)}\"\n",
    "print(f\"latitude type: {type(df_era5land['latitude'][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n",
      "nan\n",
      "False\n",
      "<NA>\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "nan_df_era5land = df_era5land[df_era5land[\"tp\"].isnull()]\n",
    "nan_df_era5land_4_random_rows = nan_df_era5land.sample(4)\n",
    "nan_df_era5land_4_random_rows_tp = nan_df_era5land_4_random_rows[\"tp\"]\n",
    "nan_df_era5land_4_random_rows_tp_1 = nan_df_era5land_4_random_rows_tp.iloc[0]\n",
    "nan_df_era5land_4_random_rows_tp_2 = nan_df_era5land_4_random_rows_tp.iloc[1]\n",
    "nan_df_era5land_4_random_rows_tp_3 = nan_df_era5land_4_random_rows_tp.iloc[2]\n",
    "nan_df_era5land_4_random_rows_tp_4 = nan_df_era5land_4_random_rows_tp.iloc[3]\n",
    "\n",
    "max_nan_df_era5land_4_random_rows_tp = max(\n",
    "    nan_df_era5land_4_random_rows_tp_1,\n",
    "    nan_df_era5land_4_random_rows_tp_2,\n",
    "    nan_df_era5land_4_random_rows_tp_3,\n",
    "    nan_df_era5land_4_random_rows_tp_4,\n",
    ")\n",
    "print(type(max_nan_df_era5land_4_random_rows_tp))\n",
    "print(max_nan_df_era5land_4_random_rows_tp)\n",
    "print(max_nan_df_era5land_4_random_rows_tp == np.nan)\n",
    "print(max_nan_df_era5land_4_random_rows_tp == pd.NA)\n",
    "print(np.isnan(max_nan_df_era5land_4_random_rows_tp))\n",
    "print(pd.isna(max_nan_df_era5land_4_random_rows_tp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upper_neighbor(lat: float, lon: float, sorted_latitudes_ascending: np.ndarray):\n",
    "    lat_idx = bisect.bisect_right(sorted_latitudes_ascending, lat)\n",
    "    if lat_idx < len(sorted_latitudes_ascending):\n",
    "        return sorted_latitudes_ascending[lat_idx], lon\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_bottom_neighbor(lat: float, lon: float, sorted_latitudes_ascending: np.ndarray):\n",
    "    lat_idx = bisect.bisect_left(sorted_latitudes_ascending, lat)\n",
    "    if lat_idx > 0:\n",
    "        return sorted_latitudes_ascending[lat_idx - 1], lon\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_left_neighbor(lat: float, lon: float, sorted_longitudes_ascending: np.ndarray):\n",
    "    lon_idx = bisect.bisect_left(sorted_longitudes_ascending, lon)\n",
    "    if lon_idx > 0:\n",
    "        return lat, sorted_longitudes_ascending[lon_idx - 1]\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_right_neighbor(lat: float, lon: float, sorted_longitudes_ascending: np.ndarray):\n",
    "    lon_idx = bisect.bisect_right(sorted_longitudes_ascending, lon)\n",
    "    if lon_idx < len(sorted_longitudes_ascending):\n",
    "        return lat, sorted_longitudes_ascending[lon_idx]\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/97658 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Square(BaseModel):\n",
    "    top_left: tuple[float, float]\n",
    "    bottom_left: tuple[float, float]\n",
    "    bottom_right: tuple[float, float]\n",
    "    top_right: tuple[float, float]\n",
    "\n",
    "\n",
    "target = np.zeros((len(lats), len(lons)), dtype=np.float32)\n",
    "\n",
    "\n",
    "def get_websirenes_keys_in_square(builder: WebSirenesBuilder, square: Square) -> list[str]:\n",
    "    websirenes_datasets_path = builder.websirenes_datasets_path\n",
    "    keys = [x.stem for x in Path(websirenes_datasets_path).glob(\"*.parquet\")]\n",
    "    websirenes_keys = []\n",
    "    for key in keys:\n",
    "        key_lat, key_lon = map(float, key.split(\"_\"))\n",
    "\n",
    "        if key_lat < square.bottom_left[0] or key_lat > square.top_left[0]:\n",
    "            continue\n",
    "        if key_lon < square.top_left[1] or key_lon > square.top_right[1]:\n",
    "            continue\n",
    "        websirenes_keys.append(key)\n",
    "    return websirenes_keys\n",
    "\n",
    "\n",
    "def _get_max_era5land_precipitation_in_square(square: Square, ds_time: xr.Dataset) -> float:\n",
    "    \"\"\"\n",
    "    This function is going to return the max precipitation in the square from ERA5Land data\n",
    "    \"\"\"\n",
    "    top_left_lat, top_left_lon = square.top_left\n",
    "    bottom_left_lat, bottom_left_lon = square.bottom_left\n",
    "    bottom_right_lat, bottom_right_lon = square.bottom_right\n",
    "    top_right_lat, top_right_lon = square.top_right\n",
    "\n",
    "    top_left = ds_time.sel(latitude=top_left_lat, longitude=top_left_lon)\n",
    "    bottom_left = ds_time.sel(latitude=bottom_left_lat, longitude=bottom_left_lon)\n",
    "    bottom_right = ds_time.sel(latitude=bottom_right_lat, longitude=bottom_right_lon)\n",
    "    top_right = ds_time.sel(latitude=top_right_lat, longitude=top_right_lon)\n",
    "\n",
    "    # top_left = top_left[\"tp\"]\n",
    "\n",
    "    assert top_left[\"tp\"].size == 1\n",
    "    assert bottom_left[\"tp\"].size == 1\n",
    "    assert bottom_right[\"tp\"].size == 1\n",
    "    assert top_right[\"tp\"].size == 1\n",
    "\n",
    "    top_left = top_left[\"tp\"].data\n",
    "    bottom_left = bottom_left[\"tp\"].data\n",
    "    bottom_right = bottom_right[\"tp\"].data\n",
    "    top_right = top_right[\"tp\"].data\n",
    "\n",
    "    max_tp = max(\n",
    "        top_left,\n",
    "        bottom_left,\n",
    "        bottom_right,\n",
    "        top_right,\n",
    "    )\n",
    "\n",
    "    if np.isnan(max_tp):\n",
    "        # yellow_color_terminal = \"\\033[93m\"\n",
    "        # reset_color_terminal = \"\\033[0m\"\n",
    "        # print(\n",
    "        #     f\"{yellow_color_terminal}Found NaN ERA5Land values in all points of the square. It means we are out of land - square {square} - returning 0.0{reset_color_terminal}\"\n",
    "        # )\n",
    "        return 0.0\n",
    "    return max_tp\n",
    "\n",
    "\n",
    "def get_precipitation_from_websirenes_keys_at_date(\n",
    "    square: Square,\n",
    "    websirenes_keys: list[str],\n",
    "    timestamp: pd.Timestamp,\n",
    "    ds_time: xr.Dataset,\n",
    ") -> float:\n",
    "    if len(websirenes_keys) == 0:\n",
    "        # yellow_color_terminal = \"\\033[93m\"\n",
    "        # reset_color_terminal = \"\\033[0m\"\n",
    "        # print(\n",
    "        #     f\"{yellow_color_terminal}Found no stations in the square {square} at {date} - using ERA5Land max precipitation in square{reset_color_terminal}\"\n",
    "        # )\n",
    "        return _get_max_era5land_precipitation_in_square(square, ds_time)\n",
    "\n",
    "    precipitations_15_min_aggregated: list[float] = []\n",
    "    for key in websirenes_keys:\n",
    "        df_web = load_websirene_dataset(key)\n",
    "\n",
    "        # print(f\"Processing station {key} at {date}\")\n",
    "        # print(df_web)\n",
    "        # if df_webs.index.tz is None:\n",
    "        #     print(f'dataframe is tz NAIVE {df_webs.index.tz}')\n",
    "        # else:\n",
    "        #     print(f'dataframe is tz AWARE {df_webs.index.tz}')\n",
    "\n",
    "        time_upper_bound = timestamp\n",
    "        time_lower_bound = timestamp - timedelta(minutes=45)\n",
    "\n",
    "        df_web_filtered = df_web[\n",
    "            (df_web.index >= time_lower_bound) & (df_web.index <= time_upper_bound)\n",
    "        ]\n",
    "\n",
    "        m15 = df_web_filtered[\"m15\"]\n",
    "\n",
    "        if m15.isnull().all():\n",
    "            # yellow_color_terminal = \"\\033[93m\"\n",
    "            # reset_color_terminal = \"\\033[0m\"\n",
    "            # print(\n",
    "            #     f\"{yellow_color_terminal}Found all NaN values in station {key} from {time_lower_bound} to {time_upper_bound} - using ERA5Land max precipitation in square{reset_color_terminal}\"\n",
    "            # )\n",
    "            precipitations_15_min_aggregated.append(\n",
    "                _get_max_era5land_precipitation_in_square(square, ds_time)\n",
    "            )\n",
    "            continue\n",
    "        precipitations_15_min_aggregated.append(m15.sum())\n",
    "\n",
    "    max_precipitation = max(precipitations_15_min_aggregated)\n",
    "    return max_precipitation\n",
    "\n",
    "\n",
    "# since we are traversing the matrix from top left to bottom right, we can use the same order to fill the target matrix\n",
    "# to do so, we need to sort the lats and lons, the lons should have higher priority than lats on the sorting:\n",
    "sorted_lats = np.sort(lats)[::-1]\n",
    "sorted_lons = np.sort(lons)\n",
    "\n",
    "sorted_latitudes_ascending = np.sort(lats)\n",
    "sorted_longitudes_ascending = np.sort(lons)\n",
    "\n",
    "\n",
    "def process_target(target: np.ndarray, ds_time: xr.Dataset, timestamp: pd.Timestamp):\n",
    "    for i, lat_i in enumerate(sorted_lats):\n",
    "        for j, lon_j in enumerate(sorted_lons):\n",
    "            # row = df_era5land[\n",
    "            #     (df_era5land.latitude == lat_i) & (df_era5land.longitude == lon_j)\n",
    "            # ]\n",
    "            # lat, lon = row[\"latitude\"].values[0], row[\"longitude\"].values[0]\n",
    "            lat, lon = lat_i, lon_j\n",
    "\n",
    "            bottom_neighbor = get_bottom_neighbor(lat, lon, sorted_latitudes_ascending)\n",
    "            if not bottom_neighbor:\n",
    "                continue\n",
    "            lat_bottom, lon_bottom = bottom_neighbor\n",
    "            right_neighbor = get_right_neighbor(lat_bottom, lon_bottom, sorted_longitudes_ascending)\n",
    "            if not right_neighbor:\n",
    "                continue\n",
    "            lat_right, lon_right = right_neighbor\n",
    "            upper_neighbor = get_upper_neighbor(lat_right, lon_right, sorted_latitudes_ascending)\n",
    "            if not upper_neighbor:\n",
    "                continue\n",
    "            lat_upper, lon_upper = upper_neighbor\n",
    "\n",
    "            square = Square(\n",
    "                top_left=(lat, lon),\n",
    "                bottom_left=(lat_bottom, lon_bottom),\n",
    "                bottom_right=(lat_right, lon_right),\n",
    "                top_right=(lat_upper, lon_upper),\n",
    "            )\n",
    "\n",
    "            websirene_keys = get_websirenes_keys_in_square(websirenes_builder, square)\n",
    "\n",
    "            # if len(websirene_keys) > 0:\n",
    "            #     green_color = \"\\033[92m\"\n",
    "            #     reset_color = \"\\033[0m\"\n",
    "            #     print(f\"\"\"\n",
    "            #         {green_color}\n",
    "            #         There are {len(websirene_keys)} stations in the square:\n",
    "            #             Left top: {square.top_left}\n",
    "            #             Left bottom: {square.bottom_left}\n",
    "            #             Right bottom: {square.bottom_right}\n",
    "            #             Right top: {square.top_right}\n",
    "            #         Stations: {websirene_keys}\n",
    "            #         {reset_color}\n",
    "            #     \"\"\")\n",
    "\n",
    "            # current_date = datetime.strptime(\n",
    "            #     \"2023-01-09T15:00:00.000000\", \"%Y-%m-%dT%H:%M:%S.%f\"\n",
    "            # )\n",
    "            websirenes_precipitation_at_date = get_precipitation_from_websirenes_keys_at_date(\n",
    "                square, websirene_keys, timestamp, ds_time\n",
    "            )\n",
    "            target[i, j] = websirenes_precipitation_at_date\n",
    "\n",
    "\n",
    "def write_target(target: np.ndarray, timestamp: pd.Timestamp):\n",
    "    target_directory = Path(\"./target\")\n",
    "    if not target_directory.exists():\n",
    "        target_directory.mkdir()\n",
    "    target_filename = target_directory / f\"{timestamp.strftime('%Y_%m_%d_%H')}.npy\"\n",
    "    # check if file exists\n",
    "    if target_filename.exists():\n",
    "        # yellow_color_terminal = \"\\033[93m\"\n",
    "        # reset_color_terminal = \"\\033[0m\"\n",
    "        # print(\n",
    "        #     f\"{yellow_color_terminal}File {target_filename} already exists - skipping{reset_color_terminal}\"\n",
    "        # )\n",
    "        return\n",
    "    np.save(target_filename, target)\n",
    "\n",
    "\n",
    "timestamps = pd.date_range(\n",
    "    start=websirenes_parser.minimum_date, end=websirenes_parser.maximum_date, freq=\"h\"\n",
    ")\n",
    "\n",
    "current_year_month = None\n",
    "ds = None\n",
    "\n",
    "for timestamp in tqdm(timestamps):\n",
    "    break\n",
    "    year = timestamp.year\n",
    "    month = timestamp.month\n",
    "    day = timestamp.day\n",
    "    hour = timestamp.hour\n",
    "\n",
    "    if current_year_month != (year, month):\n",
    "        current_year_month = (year, month)\n",
    "        df_era5land_path = f\"./ERA5Land/monthly_data/RJ_{year}_{month}.nc\"\n",
    "        if not os.path.exists(df_era5land_path):\n",
    "            raise FileNotFoundError(f\"File {df_era5land_path} not found\")\n",
    "        ds = xr.open_dataset(filename)\n",
    "        if \"expver\" in list(ds.coords.keys()):\n",
    "            # print(\">>>Oops! expver\n",
    "            # dimension found. Going to remove it.<<<\")\n",
    "            ds_combine = ds.sel(expver=1).combine_first(ds.sel(expver=5))\n",
    "            ds_combine.load()\n",
    "            ds = ds_combine\n",
    "        ds = ds[[\"u10\", \"v10\", \"d2m\", \"t2m\", \"sp\", \"tp\"]]\n",
    "\n",
    "    time = f\"{year}-{month}-{day}T{hour}:00:00.000000000\"\n",
    "    ds_time = ds.sel(time=time, method=\"nearest\")  # type: ignore\n",
    "    target = np.zeros((len(lats), len(lons)), dtype=np.float32)\n",
    "    process_target(target, ds_time, timestamp)\n",
    "    write_target(target, timestamp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atmoseer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
